{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTIFICIAL INTELLIGENCE -- CA3\n",
    "## Moein Shirdel - 810197535\n",
    "### Naive Bayes\n",
    "\n",
    "\n",
    "### Phase 1: Data pre-processing\n",
    "1) I have various methods to pre-process the given data:\n",
    "\n",
    "- Normalization: This operation normalizes a string. It can be used for a whole sentence. As en example converts full-space between plural sign (ها) and the noun to a half-space. This kind of convertions, help us to have same pattern for plural sign or verbs prefix such as (می).\n",
    "\n",
    "- Title Weight: This variable is defined at the top of the code. Generally, a comment is concatenated with its title and makes the \"opinion\" variable for each line of dataset. I train and test the system based on the \"opinion\" variable which contains both title and comment. TITLE_WEIGHT variable shows the number of copies of title in the opinion. The higher this variable is, it is counted more in the calculations. So the title's words will become more important than a single word from the comment main text. It can be helpful because the title is more likely to contain a key word that helps us to decide whether the comment recommends the product or not. This variable is set to 2, which means the title is been copied twice in the \"opinion\" variable.\n",
    "\n",
    "- Lemmatization: This operation helps in processing verbs. A verb in Persian language can be used in different shapes without having considerable difference in meaning. The lemmatizer converts each verb to its past/present base shape so they can be counted in the same group. This opertation makes the counting of verbs more meaningful.\n",
    "\n",
    "- Stemming: This operation omits the meaningles parts of a noun such as plural signs (ها، ات، ...) or (ی) from the end of the nouns. It can be useful but it seems that it does something wrong because it decreases the accuracy so much. So I didnt't use the Stemmer in the pre-processing operation.\\\n",
    "\n",
    "- Stopwords: Omiting the stopwords from the comment's words may be useful; But as I tested this method, it takes too much time to search in the list of stopwords. This opertation not only does not help us in getting better accuracy, but also decreases the accuracy by nearly 20 percents and adds about 90 seconds to the whole process! So I wrote the code for this operation bud commented it out.\n",
    "\n",
    "- Tokenize sentences: This operation is needed because we need to have the words of a comments separately and use them as a feature in training. \n",
    "\n",
    "- The omission of punctuation marks from the text can help us too because when we use Hazm library they are counted as words but cannot help us to decide that a comment is a recommendation or not. So I put them in a list named NOT_A_WORD which contains all the punctuation marks or something like them. These will not be counted as words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Calculation process\n",
    "-- At the beginning, I read the train comments. The \"opinion\" variable is tokenized. There is 2 dictionaries; one for the count of words in the recommending comments and the other for the count of worfd in the non-recommending comments. Each token will increment its value in the related dictionary by 1 unit. So at the end of the training, each dictionary will contain some keys, and the value of a key shows that how many times we've seen that key in the train comments. The conditional probabilities can be calculated based on these dictionaries.\n",
    "\n",
    "- Likelihood: this probability is the probability of appearing a specific word in a specific class which can be calculated using the dictionaries. It is calculated by dividing the frequency of a word in a class to the number of all the words of that class (additive smoothing method will be added later)\n",
    "\n",
    "- Prior probability: the probability of seeing a comment in a class (without knowing a single word of that comment) which is calculated in training. In this problem, the class prior probability is 50% since we have equal number of comments in each class. Predictor prior probability is the probability of seeing a word in a comment (without knowing the type of that comment (recommending or non-recommending))\n",
    "\n",
    "- Posterior probability: the P(c|x) shows the probability of belonging the comments to class c when we've seen the word x in that comment. This is the goal probability in our problem.\n",
    "\n",
    "- evidence: These are the information that we have and we give probabilities based on these information. For example in P(x|c) the class is the evidence variable so that we can calculate the predictor posterior probability based on the class and the dictionaries that we have learnt by training.\n",
    "\n",
    "\n",
    "Finally when the conditional probabilitiy of all words of a comment are calculated, the logarithm of those probablities are summed up for both classes and the predicted class, is the class that has a higher result.\n",
    "\n",
    "#### additive smoothing:\n",
    "3) If in a comment, there is a word that we haven't seen it in one of the classes in the training, then we will assign it to the other class based on Naive bayes formula. Because the final answer is the result of some multiplications and if there is a 0 probability for a single word, the final chance for that particular class is equal to 0 and this is wrong. \n",
    "\n",
    "4) So we add 1 (or alpha) unit(s) to the count of each word in both dictionaries so that there is not a key with 0 value. Based on the formula, 1 unit will be added to the numerator and \"d\" units will be added to the Denominator if the probability (where \"d\" is the number of different words used in that class). In this case, a single word can never specify the class of that comment. \n",
    "\n",
    "*The ALPHA value is specified at the top of code.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 3: Evaluation\n",
    "All the evaluation factors are printed at the end of the output. The best accuracy that I reached was 93.25%.\n",
    "\n",
    "5) The *Precision* value is not enough for evaluation. For example, if we detect just one comment as recommended comments correctly, the Precision value will be equal to 100% which is a wrong evaluation because we definitely have more that 1 recommended comment. Besides, The *Recall* value is not enough too. Consider an assignment in which all the comments are detected as Recommended comments. In this case, all the recommended comments are detected recommended so we get a 100% value for that which is obviously wrong.\n",
    "\n",
    "6) F1 (or f-score) is the harmonic average of Precision and Recall. It is used to balance the value of Precision and Recall cause each of them focus on different classes.  \n",
    "\n",
    "7) Evaluation Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Accuracy | Precision | Recall | F1 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| A. Smoothing + pre-proc. | 93.25% | 93.46% | 93% | 93.23% |\n",
    "| just A. Smoothing | 93.125% | 93.86% | 92.25% | 93.06% |\n",
    "| just pre-proc. | 88.37% | 84.03% | 94.75% | 89.07% |\n",
    "| none of them!! | 87.75% | 83.25% | 94.5% | 88.25% |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) As it's obvious, both of the operations improve the accuracy (even a bit). Especially Additive Smoothing which gives 4 percent more accuracy.\n",
    "\n",
    "9) \n",
    "Ex. 1: Comment #9 -- recommended detected as not-recommended\n",
    "\n",
    "title: نقد پس از خرید\n",
    "\n",
    "text: سلام ، راحت شدم از کابل شارژ ، توصیه میشود به شدت . ارزان گوشی خود را به شارژ وایرلس مجهز کنید.\n",
    "\n",
    "##### Reason: the weight given to the title may cause the fault because the title seems to be not-recommended.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Ex. 2: Comment #20 -- recommended detected as not-recommended\n",
    "\n",
    "title: خیالم راحت شد\n",
    "\n",
    "text: فندک قبلیم مدام فیوز میسوزوند و یک بار شارژر موبایل هم سوزوند ولی با این هیچ مشکلی بوجود نیومده تا الان. کیفیتش خیلی خوبه و لامپ هم داره.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Ex. 3: Comment #787 -- not-recommended detected as recommended\n",
    "\n",
    "title: کلنیل\n",
    "\n",
    "text: این نوعش به درد نمیخوره نوعش که گیاهیه خوبه.من استفاده کردم حس خوبی بهش نداشتم نسبت به نوع دیگه این برند\n",
    "\n",
    "##### Reason: multiple use of the word \"خوب\" may cause fault.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Ex. 4: Comment #775 -- recommended detected as not-recommended\n",
    "\n",
    "title: شکل ظاهری\n",
    "\n",
    "text: این کالا در طول یکروز بدستم رسید که جای تشکر داره \n",
    "منتهی کالا با عکس دیجی کالا تطابق نداره یه مدل دیگه هست ولی کاربردش یکیه . در کل خوبه ارزش خرید داره .\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Ex. 5: Comment #772 -- not-recommended detected as recommended\n",
    "\n",
    "title: اندرمعایب آچارلوله گیر14اینچ ایران پتک\n",
    "\n",
    "text: این آچار لوله گیر خیلی سنگینه،برای کارمداوم وکسانی که دست وبازوی ضعیفی دارند اصلا مناسب نیست.اگرقبل ازخریدبه دست می گرفتم،ازخریدمنصرف می شدم..\n",
    "\n",
    "\n",
    "\n",
    "-- I wrote some reasons which may cause fault in decision but every trained system may have some mistakes! :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time was 1.530883 seconds!\n",
      "Accuracy:  0.9325\n",
      "Precision:  0.9346733668341709\n",
      "Recall:  0.93\n",
      "F1:  0.9323308270676693\n",
      "                                      title  \\\n",
      "770                                   مناسب   \n",
      "771  اندرمعایب آچارلوله گیر14اینچ ایران پتک   \n",
      "772                               ماوس گرین   \n",
      "773                                بی کیفیت   \n",
      "774                               شکل ظاهری   \n",
      "775                         غیر قابل اعتماد   \n",
      "776         توضیح کوتاهی درباره ی این محصول   \n",
      "777                         بررسی کامل گوشی   \n",
      "778                        متوسط رو به بالا   \n",
      "779                                    خوبه   \n",
      "780                             جی بی ال ms   \n",
      "781                   من این محصول رو خریدم   \n",
      "782                        مناسب برای خودرو   \n",
      "783           دستگاه خوب و قابل اعتمادی است   \n",
      "784                              ماشین ماکت   \n",
      "785                           خیلی عالی هست   \n",
      "786                                   کلنیل   \n",
      "787   خیلی عالی من سفارش دادم خیلی عالی بود   \n",
      "788                      اصلا مثل عکسش نیست   \n",
      "789                               ناقص است!   \n",
      "790                                     نظر   \n",
      "791                                  مهرشاد   \n",
      "792                                   بیخود   \n",
      "793                           بوی گلاب میده   \n",
      "794                            ارزش خرید ؟!   \n",
      "795                             بسیار کوچیک   \n",
      "796                               لامپ چینی   \n",
      "797                                 خوب بود   \n",
      "798                         کیفیت خوبی داره   \n",
      "799                        از خریدم پشیمونم   \n",
      "\n",
      "                                               comment        recommend  \\\n",
      "770  به خاطر حجمش در منازل کوچک فضایی از داخل کابین...      recommended   \n",
      "771  این آچار لوله گیر خیلی سنگینه،برای کارمداوم وک...  not_recommended   \n",
      "772  یه سالی میشه که این ماوس رو دارمش تو این یک سا...      recommended   \n",
      "773  وقتی دیجی تحویل داد ناموزون و کج شده بود. اونق...  not_recommended   \n",
      "774  این کالا در طول یکروز بدستم رسید که جای تشکر د...      recommended   \n",
      "775  در اولین استفاده، برای باز کردن مهره تردمیل، ر...  not_recommended   \n",
      "776  اینکه‌درباره ی باتری گفتم ،فاجعه به تمام معناس...  not_recommended   \n",
      "777  سلام خدمت دوستان عزیز و عوامل محترم دیجی کالا\\...      recommended   \n",
      "778  درود ،دوستان قدرت تربل این باند واقعا خوبه و ر...      recommended   \n",
      "779  سلام. به نظرم توی این رنج قیمت عالیه و هیچ رقی...      recommended   \n",
      "780  تجربه من پس از دو هفته استفاده : صدای قدرتمند ...      recommended   \n",
      "781  سلام \\nمن این عطر رو از دیجیکالا خریدم و پیشنه...  not_recommended   \n",
      "782  من برا شستشوی ماشین گرفتم و از هر نظر مناسب و ...      recommended   \n",
      "783  والله من تازه خریدم این محصول رو \\nاما کیفیت س...      recommended   \n",
      "784  خرید عالی\\nزیبا\\nبه صرفه\\nمن برای فرزندم خریدم...      recommended   \n",
      "785                                 خوبه نسبت به قیمتش      recommended   \n",
      "786  این نوعش به درد نمیخوره نوعش که گیاهیه خوبه.من...  not_recommended   \n",
      "787                        بسیار زیبا و عالی و به صرفه      recommended   \n",
      "788  اینو من با توجه به عکس گرفتم ولی اصلا مثل شکلش...  not_recommended   \n",
      "789          واقعا متاسفم برای چاپ ترجمه های اینچنینی!  not_recommended   \n",
      "790  ماله من بعد ۱۰ روز استفاده قسمت لایتنینگ آی فو...  not_recommended   \n",
      "791  ۴ تا ادکلن سفارش دادم این از همه خوشبوتر بود ا...      recommended   \n",
      "792  وقتی که به دستم رسید از جعبه که در اوردم حتی ر...  not_recommended   \n",
      "793                              بوی گلبرگ و گلاب میده  not_recommended   \n",
      "794  - مهمترین ایراد مصرف غیر عادی باتری که در صورت...  not_recommended   \n",
      "795  طراحیش قشنگه ولی  داخل عکس خیلی بزرگتر ب چشم م...  not_recommended   \n",
      "796  این لامپ چینی هستتش کیفیت پایین . نور کم و فاق...  not_recommended   \n",
      "797  در کل از این خریدم راضی هستم و به تناسب قیمتش ...      recommended   \n",
      "798  تازع نصبش کردم-سرعت انتقال و نصب بازی روش عالی...      recommended   \n",
      "799  نسبت به باطری اصلی فقط 60% کار میکنه\\nالان دو ...  not_recommended   \n",
      "\n",
      "    guessed_recommendation  \n",
      "770            recommended  \n",
      "771            recommended  \n",
      "772            recommended  \n",
      "773        not_recommended  \n",
      "774        not_recommended  \n",
      "775        not_recommended  \n",
      "776        not_recommended  \n",
      "777            recommended  \n",
      "778            recommended  \n",
      "779            recommended  \n",
      "780            recommended  \n",
      "781        not_recommended  \n",
      "782            recommended  \n",
      "783            recommended  \n",
      "784            recommended  \n",
      "785            recommended  \n",
      "786            recommended  \n",
      "787            recommended  \n",
      "788        not_recommended  \n",
      "789        not_recommended  \n",
      "790        not_recommended  \n",
      "791            recommended  \n",
      "792        not_recommended  \n",
      "793        not_recommended  \n",
      "794        not_recommended  \n",
      "795        not_recommended  \n",
      "796        not_recommended  \n",
      "797            recommended  \n",
      "798            recommended  \n",
      "799        not_recommended  \n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "ALPHA = 1\n",
    "TITLE_WEIGHT = 2\n",
    "NOT_A_WORD = [\",\", \".\", \"/\", \"؟\", \"!\", \"(\", \")\", \"ـ\", \"-\", \"*\", \"**\", \"،\"]\n",
    "\n",
    "\n",
    "def count_in_class(word, recommend):\n",
    "    # prev_count = rec_count[word]\n",
    "    if recommend == 'recommended':\n",
    "        if word in rec_word_count:\n",
    "            rec_word_count[word] += 1\n",
    "        else:\n",
    "            rec_word_count[word] = 1\n",
    "    elif recommend == 'not_recommended':\n",
    "        if word in not_rec_word_count:\n",
    "            not_rec_word_count[word] += 1\n",
    "        else:\n",
    "            not_rec_word_count[word] = 1\n",
    "    return\n",
    "\n",
    "\n",
    "def parse(title, comment, recommend, is_train):\n",
    "    opinion = \"\"\n",
    "    for i in range(TITLE_WEIGHT):\n",
    "        opinion += title\n",
    "        opinion += \" \"\n",
    "\n",
    "    opinion = opinion + \" \" + comment\n",
    "    opinion = norm.normalize(opinion)\n",
    "    words = word_tokenize(opinion)\n",
    "    accepted_words = []\n",
    "    for i in range(len(words)):\n",
    "        # if words[i] not in stopwords_list():\n",
    "        if words[i] not in NOT_A_WORD:\n",
    "            words[i] = lem.lemmatize(words[i])\n",
    "            # words[i] = stemmer.stem(words[i])\n",
    "            if is_train:\n",
    "                count_in_class(words[i], recommend)\n",
    "            accepted_words.append(words[i])\n",
    "\n",
    "    return accepted_words\n",
    "\n",
    "\n",
    "def calc_conditional_prob(word):\n",
    "    if word in rec_word_count:\n",
    "        rec_count = rec_word_count[word]\n",
    "    else:\n",
    "        rec_count = 0\n",
    "    if word in not_rec_word_count:\n",
    "        not_rec_count = not_rec_word_count[word]\n",
    "    else:\n",
    "        not_rec_count = 0\n",
    "    if ALPHA > 0:\n",
    "        rec_cond = (rec_count + ALPHA) / (total_rec_words + len(rec_word_count) * ALPHA)\n",
    "        not_rec_cond = (not_rec_count + ALPHA) / (total_not_rec_words + len(not_rec_word_count) * ALPHA)\n",
    "        return math.log2(rec_cond), math.log2(not_rec_cond)\n",
    "    else:\n",
    "        return (rec_count / total_rec_words), (not_rec_count / total_not_rec_words)\n",
    "\n",
    "\n",
    "def guess_recommendation(title, comment):\n",
    "    rec_prob_log = math.log2(rec_prob)\n",
    "    not_rec_prob_log = math.log2(not_rec_prob)\n",
    "    words = parse(title, comment, \"\", False)\n",
    "    for i in range(len(words)):\n",
    "        words[i] = lem.lemmatize(words[i])\n",
    "        rec_cond, not_rec_cond = calc_conditional_prob(words[i])\n",
    "        rec_prob_log += rec_cond\n",
    "        not_rec_prob_log += not_rec_cond\n",
    "\n",
    "    if not_rec_prob_log > rec_prob_log:\n",
    "        return \"not_recommended\"\n",
    "    else:\n",
    "        return \"recommended\"\n",
    "\n",
    "\n",
    "def guess_without_additive(title, comment):\n",
    "    words = parse(title, comment, \"\", False)\n",
    "    rec_prob_comm = rec_prob\n",
    "    not_rec_prob_comm = not_rec_prob\n",
    "    for i in range(len(words)):\n",
    "        if not_rec_prob_comm == 0 or rec_prob_comm == 0:\n",
    "            break\n",
    "        words[i] = lem.lemmatize(words[i])\n",
    "        rec_cond, not_rec_cond = calc_conditional_prob(words[i])\n",
    "        rec_prob_comm *= rec_cond\n",
    "        not_rec_prob_comm *= not_rec_cond\n",
    "\n",
    "    if not_rec_prob_comm > rec_prob_comm:\n",
    "        return \"not_recommended\"\n",
    "    else:\n",
    "        return \"recommended\"\n",
    "\n",
    "\n",
    "def calc_total_words():\n",
    "    total_rec = 0\n",
    "    total_not_rec = 0\n",
    "    for key in rec_word_count:\n",
    "        total_rec += rec_word_count[key]\n",
    "    for key in not_rec_word_count:\n",
    "        total_not_rec += not_rec_word_count[key]\n",
    "\n",
    "    return total_rec, total_not_rec\n",
    "\n",
    "\n",
    "st = time.time()\n",
    "lem = Lemmatizer()\n",
    "norm = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "rec_word_count = {}\n",
    "not_rec_word_count = {}\n",
    "stopwords = stopwords_list()\n",
    "TrainDF = pd.read_csv('CA3_dataset/comment_train.csv')\n",
    "TrainDF['words'] = TrainDF.apply(lambda row: parse(row['title'], row['comment'], row['recommend'], True), axis=1)\n",
    "classes_count = TrainDF['recommend'].value_counts()\n",
    "rec_prob = classes_count['recommended'] / len(TrainDF)\n",
    "not_rec_prob = classes_count['not_recommended'] / len(TrainDF)\n",
    "total_rec_words, total_not_rec_words = calc_total_words()\n",
    "TestDF = pd.read_csv('CA3_dataset/comment_test.csv')\n",
    "\n",
    "# For removing Additive smoothing, comment the below line out AND SET THE ALPHA TO 0 !!!!\n",
    "\n",
    "TestDF['guessed_recommendation'] = TestDF.apply(lambda row: guess_recommendation(row['title'], row['comment']), axis=1)\n",
    "\n",
    "# TestDF['guessed_recommendation'] = TestDF.apply(lambda row: guess_without_additive(row['title'], row['comment']), axis=1)\n",
    "\n",
    "correct_detected_recommendation = len(TestDF[(TestDF[\"recommend\"] == \"recommended\") & (TestDF[\"guessed_recommendation\"] == \"recommended\")])\n",
    "accuracy = len(TestDF[(TestDF[\"recommend\"] == TestDF[\"guessed_recommendation\"])]) / len(TestDF)\n",
    "precision = correct_detected_recommendation / len(TestDF[(TestDF[\"guessed_recommendation\"] == \"recommended\")])\n",
    "recall = correct_detected_recommendation / len(TestDF[(TestDF[\"recommend\"] == \"recommended\")])\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "end = time.time()\n",
    "print(\"time was %f seconds!\" % (end - st))\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "print(TestDF.tail(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

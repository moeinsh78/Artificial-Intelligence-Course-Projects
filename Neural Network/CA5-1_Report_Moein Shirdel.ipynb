{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moein Shirdel -- 810197535\n",
    "## AI-CA5 - Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self, data, labels, n_classes, batch_size=None, shuffle=False):\n",
    "\n",
    "        assert len(data)==len(labels)\n",
    "        self.__n_classes = n_classes\n",
    "        self.__batch_size = batch_size\n",
    "        self.__shuffle = shuffle\n",
    "        self.__data = data\n",
    "        self.__onehot_labels = self.__onehot(labels, self.__n_classes)\n",
    "        \n",
    "    def get_onehot_labels(self):\n",
    "        return self.__onehot_labels\n",
    "    \n",
    "    def __onehot(self, labels, n_classes):\n",
    "        one_hot_targets = np.eye(self.__n_classes)[labels]\n",
    "        return np.squeeze(one_hot_targets, axis=1)\n",
    "    \n",
    "    def __shuffle_dataset(self):\n",
    "        order = np.random.permutation(len(self.__data))\n",
    "        self.__data = self.__data[order]\n",
    "        self.__onehot_labels = self.__onehot_labels[order]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        if self.__shuffle:\n",
    "            self.__shuffle_dataset()\n",
    "            \n",
    "        if self.__batch_size==None:\n",
    "            yield (np.matrix(self.__data), np.matrix(self.__onehot_labels))\n",
    "            return\n",
    "            \n",
    "        for idx in range(0, len(self.__data), self.__batch_size):\n",
    "            yield (np.matrix(self.__data[idx:idx+self.__batch_size]), \n",
    "                   np.matrix(self.__onehot_labels[idx:idx+self.__batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identical:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        identical_value = np.matrix(matrix, dtype=float)\n",
    "        return identical_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
    "        return identical_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "\n",
    "class Relu:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __relu(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype = float)\n",
    "        relu_value = np.where(temp > 0, temp, 0)\n",
    "        return relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype = float)\n",
    "        relu_derivative_value = np.where(temp > 0, 1, 0)\n",
    "        return relu_derivative_value\n",
    "    \n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__relu(matrix)\n",
    "\n",
    "    \n",
    "class LeakyRelu:\n",
    "    \n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        self.negative_slope = 0.01\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        leaky_relu_value = np.where(temp > 0, temp, temp * self.negative_slope)\n",
    "        return leaky_relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        leaky_relu_derivative = np.where(temp > 0, 1, self.negative_slope)\n",
    "        return leaky_relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        temp = (-1) * np.matrix(matrix, dtype=float)\n",
    "        sigmoid_value = 1/(1 + np.exp((temp)))\n",
    "        return sigmoid_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        sigmoid_derivative = np.matrix(np.array(self.__val(matrix)) * np.array(1 - self.__val(matrix)),dtype=float) \n",
    "        return sigmoid_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        temp = temp - temp.max()\n",
    "        softmax_value = np.exp(temp) / np.sum(np.exp(temp)) \n",
    "        return softmax_value\n",
    "\n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy: #(with softmax)\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        SM = Softmax()\n",
    "        softmax_out = np.matrix(true_val)\n",
    "        for i in range(len(true_val)):\n",
    "            softmax_out[i] = SM(true_val[i])\n",
    "        cross_entropy_value = np.matrix(- np.array(expected_val) * np.log(np.array(softmax_out + 1e-9))\n",
    "                                               ,dtype=float)\n",
    "        \n",
    "        return cross_entropy_value\n",
    "        \n",
    "    def derivative(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        SM = Softmax()\n",
    "        softmax_out = np.matrix(true_val)\n",
    "        for i in range(len(true_val)):\n",
    "            softmax_out[i] = SM(true_val[i])\n",
    "        cross_entropy_derivative = softmax_out - expected_val\n",
    "        return cross_entropy_derivative\n",
    "    \n",
    "    def __call__(self, true_val, expected_val):\n",
    "        return self.__val(true_val, expected_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, DEFAULT_VAR = 0, 0.05, 0., 1.\n",
    "  \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=Identical(), initial_weight='uniform', **initializing_parameters):\n",
    "        \n",
    "        assert type(initial_weight)==str, 'Undefined activation function!'\n",
    "        \n",
    "        self.__weight_initializer_dict = {'uniform':self.__uniform_weight, 'normal':self.__normal_weight}\n",
    "        \n",
    "        self.__n_neurons = output_size\n",
    "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
    "        self.__weight = weight_initializer(input_size, self.__n_neurons, **initializing_parameters)\n",
    "        self.__bias = weight_initializer(1, self.__n_neurons, **initializing_parameters)\n",
    "        self.__activation = activation\n",
    "        \n",
    "        self.__last_input = None\n",
    "        self.__last_activation_input = None\n",
    "        self.__last_activation_output = None\n",
    "        self.__last_activation_derivative = None\n",
    "        \n",
    "\n",
    "    def forward(self, layer_input):\n",
    "        assert np.ndim(layer_input)==2\n",
    "        assert np.size(self.__weight,0) == np.size(layer_input,1)\n",
    "        self.__last_input = np.matrix(layer_input)\n",
    "        self.__last_activation_input = (self.__last_input * self.__weight) + self.__bias\n",
    "        self.__last_activation_output = self.__activation(self.__last_activation_input)\n",
    "        self.__last_activation_derivative = self.__activation.derivative(self.__last_activation_input)\n",
    "        return self.__last_activation_output\n",
    "    \n",
    "    def update_weights(self, backprop_tensor, lr):\n",
    "        assert np.ndim(backprop_tensor)==2\n",
    "        assert np.size(backprop_tensor,0) == np.size(self.__last_activation_derivative,0)\n",
    "        assert np.size(backprop_tensor,1) == self.__n_neurons\n",
    "        \n",
    "        W_tr = np.matrix(self.__weight)\n",
    "        W_tr = W_tr.transpose()\n",
    "        X_tr = self.__last_input.transpose()\n",
    "        ones = np.ones(np.shape(self.__last_input), dtype = float)\n",
    "        ones_tr = ones.transpose()\n",
    "        \n",
    "        dL_dA = np.matrix((np.array(backprop_tensor) * np.array(self.__last_activation_derivative)), dtype = float)\n",
    "        dL_dW = X_tr * dL_dA\n",
    "        dL_dB = np.sum(dL_dA, axis=0)\n",
    "        \n",
    "        self.__weight = self.__weight - lr * dL_dW\n",
    "        self.__bias = self.__bias - lr * dL_dB\n",
    "#         print(\"Layer weights: \")\n",
    "#         print(self.__weight)\n",
    "        backprop_tensor = dL_dA * W_tr\n",
    "        \n",
    "        return backprop_tensor\n",
    "\n",
    "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
    "        if 'low' in initializing_parameters.keys(): low = initializing_parameters['low']\n",
    "        if 'high' in initializing_parameters.keys(): high = initializing_parameters['high']\n",
    "        weights = np.random.uniform(low, high, (dim1, dim2)) \n",
    "        return weights\n",
    "\n",
    "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
    "        if 'mean' in initializing_parameters.keys(): mean = initializing_parameters['mean']\n",
    "        if 'var' in initializing_parameters.keys(): var = initializing_parameters['var']\n",
    "        weights = np.random.normal(mean, np.sqrt(var), (dim1, dim2))\n",
    "        return weights\n",
    "    \n",
    "    @property\n",
    "    def n_neurons(self): return self.__n_neurons\n",
    "    \n",
    "    @property\n",
    "    def weight(self): return self.__weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self): return self.__bias\n",
    "    \n",
    "    @property\n",
    "    def activation(self): return self.__activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "        \n",
    "        self.__layers_list = []\n",
    "        \n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "\n",
    "        \n",
    "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):\n",
    "         \n",
    "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
    "        \n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
    "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
    "        self.__layers_list.append(new_layer)\n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
    "      \n",
    "    \n",
    "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
    "        assert self.__layers_list, \"Uncomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = lr\n",
    "    \n",
    "            \n",
    "    def get_2Dout(self, network_input):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        for i in range(len(self.__layers_list)):\n",
    "            if i == 0:\n",
    "                layer_result = self.__layers_list[i].forward(network_input)\n",
    "            else:\n",
    "                layer_result = self.__layers_list[i].forward(layer_result)\n",
    "            if i == len(self.__layers_list) - 2:\n",
    "                return layer_result\n",
    "    \n",
    "    \n",
    "    def forward(self, network_input):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        for i in range(len(self.__layers_list)):\n",
    "            if i == 0:\n",
    "                layer_result = self.__layers_list[i].forward(network_input)\n",
    "            else:\n",
    "                layer_result = self.__layers_list[i].forward(layer_result)\n",
    "        \n",
    "        network_output = layer_result\n",
    "        return network_output\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
    "        \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            if print_results: \n",
    "                print('Epoch {}:'.format(epoch)) \n",
    "                \n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "            \n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "                    \n",
    "        return log\n",
    "    \n",
    "    \n",
    "    def __train(self, trainloader):\n",
    "        batch_accuracies, batch_losses = [], []\n",
    "        for x_train, y_train in trainloader:\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
    "            batch_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(batch_accuracies), np.mean(batch_losses)\n",
    "    \n",
    "    \n",
    "    def __test(self, testloader):\n",
    "        batch_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            batch_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(batch_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    \n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        \n",
    "        back = self.forward(x_batch)\n",
    "        last_layer_output = self.__get_labels(back)\n",
    "        self.__update_weights(back, y_batch)\n",
    "        batch_accuracy = self.__compute_accuracy(last_layer_output, y_batch)\n",
    "        CE = CrossEntropy()\n",
    "        batch_whole_loss = CE(last_layer_output, y_batch)\n",
    "        batch_average_loss = sum(batch_whole_loss) / len(batch_whole_loss)\n",
    "        \n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "\n",
    "        \n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        \n",
    "        last_layer_output = self.forward(x_batch)\n",
    "        last_layer_output = self.__get_labels(last_layer_output)\n",
    "        batch_accuracy = self.__compute_accuracy(last_layer_output, y_batch)\n",
    "        CE = CrossEntropy()\n",
    "        batch_whole_loss = CE(last_layer_output, y_batch)\n",
    "        batch_average_loss = sum(batch_whole_loss) / len(batch_whole_loss)\n",
    "        \n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "            \n",
    "        \n",
    "    def __get_labels(self, outputs):\n",
    "        labels = outputs\n",
    "        for i in range(len(outputs)):\n",
    "            index = np.argmax(outputs[i])\n",
    "            for j in range(len(outputs[i])):\n",
    "                if(j == index):\n",
    "                    labels[i,j] = 1.\n",
    "                else:\n",
    "                    labels[i,j] = 0.\n",
    "\n",
    "        labels = np.matrix(labels)\n",
    "        return labels\n",
    "    \n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "        correct = 0\n",
    "        index = 0\n",
    "        for expected_label in expected_output:\n",
    "            predicted_label = output[index]\n",
    "            if(np.argmax(predicted_label) == np.argmax(expected_label)):\n",
    "                correct += 1\n",
    "            index += 1\n",
    "        accuracy = correct / len(output) \n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def __update_weights(self, output, y_train):\n",
    "        backprop_tensor = CrossEntropy().derivative(output, y_train)\n",
    "        for i in range(len(self.__layers_list) - 1, -1, -1):\n",
    "            backprop_tensor = self.__layers_list[i].update_weights(backprop_tensor, self.__lr)\n",
    "            \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample code for building and training a model\n",
    "def data_preprocessor(data):\n",
    "    data = np.matrix(data)\n",
    "    data = data / 256\n",
    "    return data\n",
    "    \n",
    "def label_preprocessor(labels):\n",
    "    labels = np.matrix(labels)\n",
    "    labels = labels.transpose()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = np.genfromtxt('./Fashion-MNIST/trainData.csv', delimiter=',')\n",
    "train_labels = np.genfromtxt('./Fashion-MNIST/trainLabels.csv', delimiter=',', dtype = int)\n",
    "test_data = np.genfromtxt('./Fashion-MNIST/testData.csv', delimiter=',')\n",
    "test_labels = np.genfromtxt('./Fashion-MNIST/testLabels.csv', delimiter=',', dtype = int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.2903\tAverage Loss: 0.18377452298984032\n",
      "\tTest: Average Accuracy: 0.47653753993610226\tAverage Loss: 0.1348980291872519\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.59885\tAverage Loss: 0.11454449751357636\n",
      "\tTest: Average Accuracy: 0.6561501597444089\tAverage Loss: 0.09738756311296334\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6837\tAverage Loss: 0.08593858817080884\n",
      "\tTest: Average Accuracy: 0.6924920127795527\tAverage Loss: 0.08064018206033857\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7253333333333334\tAverage Loss: 0.07468171335182307\n",
      "\tTest: Average Accuracy: 0.7322284345047924\tAverage Loss: 0.07316660057694017\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7566666666666667\tAverage Loss: 0.0679543551591154\n",
      "\tTest: Average Accuracy: 0.7584864217252396\tAverage Loss: 0.06704808136285832\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7781666666666667\tAverage Loss: 0.06278334791670526\n",
      "\tTest: Average Accuracy: 0.7718650159744409\tAverage Loss: 0.06283833736385856\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.79625\tAverage Loss: 0.05889034987920136\n",
      "\tTest: Average Accuracy: 0.7929313099041534\tAverage Loss: 0.05963411296354732\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8097\tAverage Loss: 0.05588601201177143\n",
      "\tTest: Average Accuracy: 0.8049121405750799\tAverage Loss: 0.057147285395938614\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8177166666666666\tAverage Loss: 0.05362991960623149\n",
      "\tTest: Average Accuracy: 0.8117012779552716\tAverage Loss: 0.054955999236409724\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8239666666666666\tAverage Loss: 0.05174758561444068\n",
      "\tTest: Average Accuracy: 0.8169928115015974\tAverage Loss: 0.05342494097328827\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8292333333333334\tAverage Loss: 0.05027242758719186\n",
      "\tTest: Average Accuracy: 0.8222843450479234\tAverage Loss: 0.052305536437329284\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.83315\tAverage Loss: 0.049006003279629985\n",
      "\tTest: Average Accuracy: 0.8246805111821086\tAverage Loss: 0.05151529373233273\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8353666666666667\tAverage Loss: 0.04801568698761707\n",
      "\tTest: Average Accuracy: 0.8278753993610224\tAverage Loss: 0.05042352246558987\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8378666666666666\tAverage Loss: 0.047129447454046104\n",
      "\tTest: Average Accuracy: 0.8300718849840255\tAverage Loss: 0.0499628267994682\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8408833333333333\tAverage Loss: 0.046399260856179965\n",
      "\tTest: Average Accuracy: 0.830970447284345\tAverage Loss: 0.04933018821318649\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8424166666666667\tAverage Loss: 0.04577928056924405\n",
      "\tTest: Average Accuracy: 0.830870607028754\tAverage Loss: 0.04883006947366017\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8444333333333334\tAverage Loss: 0.045191387695630275\n",
      "\tTest: Average Accuracy: 0.8313698083067093\tAverage Loss: 0.04811897217267349\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8464\tAverage Loss: 0.04460835236588391\n",
      "\tTest: Average Accuracy: 0.8305710862619808\tAverage Loss: 0.04869358017593446\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8489\tAverage Loss: 0.04415854382717227\n",
      "\tTest: Average Accuracy: 0.8358626198083067\tAverage Loss: 0.047202622849785436\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8498\tAverage Loss: 0.0437092997210572\n",
      "\tTest: Average Accuracy: 0.8370607028753994\tAverage Loss: 0.04692969283802044\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8504166666666667\tAverage Loss: 0.04327008808023085\n",
      "\tTest: Average Accuracy: 0.8335662939297125\tAverage Loss: 0.04691112795642895\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8520833333333333\tAverage Loss: 0.04294586005537608\n",
      "\tTest: Average Accuracy: 0.8347643769968051\tAverage Loss: 0.04705586135711266\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8529666666666667\tAverage Loss: 0.04262914836497898\n",
      "\tTest: Average Accuracy: 0.8353634185303515\tAverage Loss: 0.046696475631510276\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.85525\tAverage Loss: 0.0422646019897593\n",
      "\tTest: Average Accuracy: 0.8383586261980831\tAverage Loss: 0.045885200363499884\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.85575\tAverage Loss: 0.04198376674400923\n",
      "\tTest: Average Accuracy: 0.8390575079872205\tAverage Loss: 0.04565012304411892\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8562166666666666\tAverage Loss: 0.04167201923057885\n",
      "\tTest: Average Accuracy: 0.8383586261980831\tAverage Loss: 0.04586744618113881\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8576666666666667\tAverage Loss: 0.04146108025345271\n",
      "\tTest: Average Accuracy: 0.8422523961661342\tAverage Loss: 0.0451031153675017\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8574833333333334\tAverage Loss: 0.04117063323937106\n",
      "\tTest: Average Accuracy: 0.8393570287539937\tAverage Loss: 0.04525611681602418\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8585666666666667\tAverage Loss: 0.04095927495460992\n",
      "\tTest: Average Accuracy: 0.8422523961661342\tAverage Loss: 0.044576991639832184\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8595833333333334\tAverage Loss: 0.040698002931572365\n",
      "\tTest: Average Accuracy: 0.838158945686901\tAverage Loss: 0.045554143783739925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The whole network has been designed with the codes above. I've added the things needed for the report.\n",
    "\n",
    "### Level 1: Data Preprocessing\n",
    "\n",
    "1- Showing a record (data row) from the dataset for each class:\n",
    "The first data row of each class has been printed (as an example) using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for class number 9:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.  13.  73.   0.   0.   1.   4.   0.   0.   0.   0.   1.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   0.\n",
      "  36. 136. 127.  62.  54.   0.   0.   0.   1.   3.   4.   0.   0.   3.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.\n",
      " 102. 204. 176. 134. 144. 123.  23.   0.   0.   0.   0.  12.  10.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 155. 236. 207. 178. 107. 156. 161. 109.  64.  23.  77. 130.  72.  15.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  69.\n",
      " 207. 223. 218. 216. 216. 163. 127. 121. 122. 146. 141.  88. 172.  66.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   1.   0. 200.\n",
      " 232. 232. 233. 229. 223. 223. 215. 213. 164. 127. 123. 196. 229.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 183.\n",
      " 225. 216. 223. 228. 235. 227. 224. 222. 224. 221. 223. 245. 173.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 193.\n",
      " 228. 218. 213. 198. 180. 212. 210. 211. 213. 223. 220. 243. 202.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   3.   0.  12. 219.\n",
      " 220. 212. 218. 192. 169. 227. 208. 218. 224. 212. 226. 197. 209.  52.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.  99. 244.\n",
      " 222. 220. 218. 203. 198. 221. 215. 213. 222. 220. 245. 119. 167.  56.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   0.   0.  55. 236.\n",
      " 228. 230. 228. 240. 232. 213. 218. 223. 234. 217. 217. 209.  92.   0.\n",
      "   0.   0.   1.   4.   6.   7.   2.   0.   0.   0.   0.   0. 237. 226.\n",
      " 217. 223. 222. 219. 222. 221. 216. 223. 229. 215. 218. 255.  77.   0.\n",
      "   0.   3.   0.   0.   0.   0.   0.   0.   0.  62. 145. 204. 228. 207.\n",
      " 213. 221. 218. 208. 211. 218. 224. 223. 219. 215. 224. 244. 159.   0.\n",
      "   0.   0.   0.   0.  18.  44.  82. 107. 189. 228. 220. 222. 217. 226.\n",
      " 200. 205. 211. 230. 224. 234. 176. 188. 250. 248. 233. 238. 215.   0.\n",
      "   0.  57. 187. 208. 224. 221. 224. 208. 204. 214. 208. 209. 200. 159.\n",
      " 245. 193. 206. 223. 255. 255. 221. 234. 221. 211. 220. 232. 246.   0.\n",
      "   3. 202. 228. 224. 221. 211. 211. 214. 205. 205. 205. 220. 240.  80.\n",
      " 150. 255. 229. 221. 188. 154. 191. 210. 204. 209. 222. 228. 225.   0.\n",
      "  98. 233. 198. 210. 222. 229. 229. 234. 249. 220. 194. 215. 217. 241.\n",
      "  65.  73. 106. 117. 168. 219. 221. 215. 217. 223. 223. 224. 229.  29.\n",
      "  75. 204. 212. 204. 193. 205. 211. 225. 216. 185. 197. 206. 198. 213.\n",
      " 240. 195. 227. 245. 239. 223. 218. 212. 209. 222. 220. 221. 230.  67.\n",
      "  48. 203. 183. 194. 213. 197. 185. 190. 194. 192. 202. 214. 219. 221.\n",
      " 220. 236. 225. 216. 199. 206. 186. 181. 177. 172. 181. 205. 206. 115.\n",
      "   0. 122. 219. 193. 179. 171. 183. 196. 204. 210. 213. 207. 211. 210.\n",
      " 200. 196. 194. 191. 195. 191. 198. 192. 176. 156. 167. 177. 210.  92.\n",
      "   0.   0.  74. 189. 212. 191. 175. 172. 175. 181. 185. 188. 189. 188.\n",
      " 193. 198. 204. 209. 210. 210. 211. 188. 188. 194. 192. 216. 170.   0.\n",
      "   2.   0.   0.   0.  66. 200. 222. 237. 239. 242. 246. 243. 244. 221.\n",
      " 220. 193. 191. 179. 182. 182. 181. 176. 166. 168.  99.  58.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  40.  61.  44.  72.  41.  35.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 0:\n",
      "[  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  41. 188. 103.  54.\n",
      "  48.  43.  87. 168. 133.  16.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   0.   0.   0.  49. 136. 219. 216. 228. 236. 255.\n",
      " 255. 255. 255. 217. 215. 254. 231. 160.  45.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  14. 176. 222. 224. 212. 203. 198. 196. 200.\n",
      " 215. 204. 202. 201. 201. 201. 209. 218. 224. 164.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 188. 219. 200. 198. 202. 198. 199. 199. 201.\n",
      " 196. 198. 198. 200. 200. 200. 200. 201. 200. 225.  41.   0.   0.   0.\n",
      "   0.   0.   0.   0.  51. 219. 199. 203. 203. 212. 238. 248. 250. 245.\n",
      " 249. 246. 247. 252. 248. 235. 207. 203. 203. 222. 140.   0.   0.   0.\n",
      "   0.   0.   0.   0. 116. 226. 206. 204. 207. 204. 101.  75.  47.  73.\n",
      "  48.  50.  45.  51.  63. 113. 222. 202. 206. 220. 224.   0.   0.   0.\n",
      "   0.   0.   0.   0. 200. 222. 209. 203. 215. 200.   0.  70.  98.   0.\n",
      " 103.  59.  68.  71.  49.   0. 219. 206. 214. 210. 250.  38.   0.   0.\n",
      "   0.   0.   0.   0. 247. 218. 212. 210. 215. 214.   0. 254. 243. 139.\n",
      " 255. 174. 251. 255. 205.   0. 215. 217. 214. 208. 220.  95.   0.   0.\n",
      "   0.   0.   0.  45. 226. 214. 214. 215. 224. 205.   0.  42.  35.  60.\n",
      "  16.  17.  12.  13.  70.   0. 189. 216. 212. 206. 212. 156.   0.   0.\n",
      "   0.   0.   0. 164. 235. 214. 211. 220. 216. 201.  52.  71.  89.  94.\n",
      "  83.  78.  70.  76.  92.  87. 206. 207. 222. 213. 219. 208.   0.   0.\n",
      "   0.   0.   0. 106. 187. 223. 237. 248. 211. 198. 252. 250. 248. 245.\n",
      " 248. 252. 253. 250. 252. 239. 201. 212. 225. 215. 193. 113.   0.   0.\n",
      "   0.   0.   0.   0.   0.  17.  54. 159. 222. 193. 208. 192. 197. 200.\n",
      " 200. 200. 200. 201. 203. 195. 210. 165.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  47. 225. 192. 214. 203. 206. 204.\n",
      " 204. 205. 206. 204. 212. 197. 218. 107.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   1.   6.   0.  46. 212. 195. 212. 202. 206. 205.\n",
      " 204. 205. 206. 204. 212. 200. 218.  91.   0.   3.   1.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.  11. 197. 199. 205. 202. 205. 206.\n",
      " 204. 205. 207. 204. 205. 205. 218.  77.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   3.   0.   2. 191. 198. 201. 205. 206. 205.\n",
      " 205. 206. 209. 206. 199. 209. 219.  74.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   2.   0.   0. 188. 197. 200. 207. 207. 204.\n",
      " 207. 207. 210. 208. 198. 207. 221.  72.   0.   4.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   2.   0.   0. 215. 198. 203. 206. 208. 205.\n",
      " 207. 207. 210. 208. 200. 202. 222.  75.   0.   4.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 212. 198. 209. 206. 209. 206.\n",
      " 208. 207. 211. 206. 205. 198. 221.  80.   0.   3.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 204. 201. 205. 208. 207. 205.\n",
      " 211. 205. 210. 210. 209. 195. 221.  96.   0.   3.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 202. 201. 205. 209. 207. 205.\n",
      " 213. 206. 210. 209. 210. 194. 217. 105.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 204. 204. 205. 208. 207. 205.\n",
      " 215. 207. 210. 208. 211. 193. 213. 115.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 204. 207. 207. 208. 206. 206.\n",
      " 215. 210. 210. 207. 212. 195. 210. 118.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 198. 208. 208. 208. 204. 207.\n",
      " 212. 212. 210. 207. 211. 196. 207. 121.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 198. 210. 207. 208. 206. 209.\n",
      " 213. 212. 211. 207. 210. 197. 207. 124.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 172. 210. 203. 201. 199. 204.\n",
      " 207. 205. 204. 201. 205. 197. 206. 127.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 188. 221. 214. 234. 236. 238.\n",
      " 244. 244. 244. 240. 243. 214. 224. 162.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 139. 146. 130. 135. 135. 137.\n",
      " 125. 124. 125. 121. 119. 114. 130.  76.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 3:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.  33.  96. 175. 156.  64.  14.\n",
      "  54. 137. 204. 194. 102.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  73. 186. 177. 183. 175. 188. 232. 255.\n",
      " 223. 219. 194. 179. 186. 213. 146.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  35. 163. 140. 150. 152. 150. 146. 175. 175.\n",
      " 173. 171. 156. 152. 148. 129. 156. 140.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 150. 142. 140. 152. 160. 156. 146. 142. 127.\n",
      " 135. 133. 140. 140. 137. 133. 125. 169.  75.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  54. 167. 146. 129. 142. 137. 137. 131. 148.\n",
      " 148. 133. 131. 131. 131. 125. 140. 140.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 110. 188. 133. 146. 152. 133. 125. 127.\n",
      " 119. 129. 133. 119. 140. 131. 150.  14.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 221. 158. 137. 135. 123. 110. 110.\n",
      " 114. 108. 112. 117. 127. 142.  77.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   4.   0.  25. 158. 137. 125. 119. 119. 110.\n",
      " 117. 117. 110. 119. 127. 144.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 123. 156. 129. 112. 110. 102.\n",
      " 112. 100. 121. 117. 129. 114.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 125. 169. 127. 119. 106. 108.\n",
      " 104.  94. 121. 114. 129.  91.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  98. 171. 129. 112. 104. 114.\n",
      " 106. 102. 112. 104. 133.  64.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  66. 173. 135. 129.  98. 100.\n",
      " 119. 102. 108.  98. 135.  60.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  56. 171. 135. 127. 100. 108.\n",
      " 117.  85. 106. 110. 135.  66.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  52. 150. 129. 110. 100.  91.\n",
      " 102.  94.  83. 104. 123.  66.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  66. 167. 140. 148. 148. 127.\n",
      " 137. 152. 146. 146. 148.  96.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  45. 123.  94. 104.  96. 119.\n",
      " 121. 106.  98. 112.  87. 114.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 106.  89.  58.  50.  37.  50.\n",
      "  66.  56.  50.  75.  75. 137.  22.   0.   2.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   2.   0.  29. 148. 114. 106. 125.  89. 100.\n",
      " 133. 117. 131. 131. 131. 125. 112.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 100. 106. 114.  91. 137.  62. 102.\n",
      " 131.  89. 135. 112. 131. 108. 135.  37.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 146. 100. 108.  98. 144.  62. 106.\n",
      " 131.  87. 133. 104. 160. 117. 121.  68.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  33. 121. 108.  96. 100. 140.  71. 106.\n",
      " 127.  85. 140. 104. 150. 140. 114.  89.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  62. 119. 112. 102. 110. 137.  75. 106.\n",
      " 144.  81. 144. 108. 117. 154. 117. 104.  18.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  66. 121. 102. 112. 117. 131.  73. 104.\n",
      " 156.  77. 137. 135.  83. 179. 129. 121.  35.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 127.  81. 125. 133. 119.  79. 100.\n",
      " 169.  83. 129. 175.  60. 163. 135. 146.  39.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 106. 129.  62. 140. 144. 108.  85.  83.\n",
      " 158.  85. 129. 175.  48. 146. 133. 135.  64.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 117. 119.  79. 140. 152. 102.  89. 110.\n",
      " 137.  96. 150. 196.  83. 144. 135. 133.  77.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 154. 121.  87. 140. 154. 112.  94.  52.\n",
      " 142. 100.  83. 152.  85. 160. 133. 100.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   4.   0.   2.   0.  35.   4.  33.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 2:\n",
      "[  0.   0.   0.   0.   1.   0.   0.   0.   0.  22.  88. 188. 172. 132.\n",
      " 125. 141. 199. 143.   9.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   0.   0.  20. 131. 199. 206. 196. 202. 242. 255.\n",
      " 255. 250. 222. 197. 206. 188. 126.  17.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   0.  35. 214. 191. 183. 178. 175. 168. 150. 162.\n",
      " 159. 152. 158. 179. 183. 189. 195. 185.  82.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 170. 190. 172. 177. 176. 171. 169. 162. 155.\n",
      " 148. 154. 169. 174. 175. 175. 177. 183. 188.  12.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  25. 194. 180. 178. 174. 184. 187. 189. 187. 184.\n",
      " 181. 189. 200. 197. 193. 190. 178. 175. 194.  90.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  42. 218. 191. 197. 208. 204. 211. 209. 210. 212.\n",
      " 211. 214. 215. 213. 214. 211. 211. 191. 200. 158.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  88. 221. 215. 217. 219. 211. 185. 150. 118. 107.\n",
      "  99.  88.  83.  90. 135. 212. 203. 207. 219. 169.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  27. 118. 162.  40.   0.   0.   0.  10.  19.\n",
      "  28.  39.  47.  36.   0.   0. 203. 230. 220. 203.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 138. 136.  71.  69.  54. 216. 217. 203. 184. 168.\n",
      " 163. 162. 163. 178. 221. 186.  38.  26.   7.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  67. 134. 154. 224. 129.  66.  81. 117. 129. 128.\n",
      " 132. 137. 131. 129.  86.  73. 157. 151. 134. 216.  18.   0.   0.   0.\n",
      "   0.   0.   0.   0. 203. 198. 172. 183. 206. 255. 255. 250. 243. 240.\n",
      " 239. 235. 238. 244. 255. 238. 184. 160.  86.  98.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 122. 188. 224. 151. 105. 127.  97. 100. 105. 114.\n",
      " 117. 117. 113. 103.  98. 111. 142. 254. 191. 255.  49.   0.   0.   0.\n",
      "   0.   0.   0.   0. 163. 179. 200.  95. 154. 198. 197. 200. 200. 198.\n",
      " 197. 198. 199. 202. 200. 176.  86. 206. 157. 162.  10.   0.   0.   0.\n",
      "   0.   0.   0.   0. 197. 201. 229.  71. 144. 194. 181. 183. 179. 182.\n",
      " 180. 179. 180. 190. 185. 197.  76. 219. 185. 201.  34.   0.   0.   0.\n",
      "   0.   0.   0.   0. 199. 193. 226.  58. 154. 192. 184. 187. 184. 186.\n",
      " 184. 185. 183. 192. 191. 200.  56. 219. 203. 207.  60.   0.   0.   0.\n",
      "   0.   0.   0.   0. 201. 194. 224.  41. 163. 190. 186. 186. 184. 185.\n",
      " 183. 185. 178. 190. 194. 202.  33. 211. 200. 206.  73.   0.   0.   0.\n",
      "   0.   0.   0.   0. 201. 197. 222.  17. 172. 190. 186. 187. 182. 186.\n",
      " 185. 187. 180. 187. 193. 202.  26. 212. 202. 203.  76.   0.   0.   0.\n",
      "   0.   0.   0.   0. 200. 197. 223.   0. 177. 189. 184. 185. 178. 184.\n",
      " 183. 184. 180. 183. 189. 203.  35. 196. 203. 203.  84.   0.   0.   0.\n",
      "   0.   0.   0.   0. 200. 197. 223.   0. 185. 187. 185. 187. 180. 184.\n",
      " 182. 183. 178. 182. 183. 205.  44. 159. 207. 201.  85.   0.   0.   0.\n",
      "   0.   0.   0.   0. 187. 198. 225.   0. 194. 188. 184. 185. 180. 183.\n",
      " 183. 184. 181. 181. 177. 206.  46. 129. 211. 200.  88.   0.   0.   0.\n",
      "   0.   0.   0.   6. 186. 200. 211.   0. 199. 189. 184. 184. 185. 182.\n",
      " 183. 184. 185. 182. 175. 205.  50.  97. 216. 197.  93.   0.   0.   0.\n",
      "   0.   0.   0.   5. 185. 204. 184.   0. 202. 188. 182. 182. 183. 183.\n",
      " 184. 182. 180. 182. 174. 202.  63.  59. 220. 196.  94.   0.   0.   0.\n",
      "   0.   0.   0.   5. 184. 206. 157.   0. 204. 187. 187. 189. 192. 190.\n",
      " 190. 191. 190. 187. 183. 202.  78.  35. 222. 197.  95.   0.   0.   0.\n",
      "   0.   0.   0.   5. 183. 208. 127.   0. 197. 166. 153. 149. 149. 146.\n",
      " 148. 149. 150. 151. 158. 191.  90.   8. 223. 195.  99.   0.   0.   0.\n",
      "   0.   0.   0.   6. 184. 208. 114.   0. 204. 173. 161. 180. 176. 172.\n",
      " 173. 173. 174. 176. 162. 202. 115.   0. 229. 199. 105.   0.   0.   0.\n",
      "   0.   0.   0.   9. 178. 204. 115.   0. 121. 135. 114. 117. 114. 114.\n",
      " 117. 118. 119. 117. 113. 147.  63.   0. 225. 196. 107.   0.   0.   0.\n",
      "   0.   0.   0.  18. 180. 206. 131.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 224. 197. 123.   0.   0.   0.\n",
      "   0.   0.   0.   0. 141. 151.  76.   0.   1.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 133. 167.  73.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 7:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   0.   3.   1.\n",
      "   0.   4.   0.   0.   0.   2.   0.   0.   0.   0.   5.   1.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   0.\n",
      "   0.   0.   0.   0. 106. 229.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      "   0.  90. 138. 223. 214. 209. 167.   0.   0.   0.   6. 124.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  37. 122.\n",
      " 179. 249. 214. 195. 181. 213. 241.   0.   0.   0.  94. 179.   0.   0.\n",
      "   0.   0.   0.   2.   0.   6.   0.   0.   0.   0.  16. 149. 236. 226.\n",
      " 201. 195. 200. 204. 155. 209. 116.   0.  22. 109. 251.  35.  51.   0.\n",
      "   0.   0.   1.   3.   0.   0.   0.   0.  67. 150. 240. 221. 194. 190.\n",
      " 204. 214. 205. 195. 207. 185. 206. 233. 224. 179.   2.  10.  22.   0.\n",
      "   0.   0.   0.   0.   0.   0. 110. 214. 237. 209. 196. 192. 215. 215.\n",
      " 213. 213. 207. 193. 186. 199. 206. 175.   0.   0. 124. 230. 200.  36.\n",
      "   0.  50. 119. 158. 166. 192. 204. 198. 187. 202. 203. 211. 214. 204.\n",
      " 209. 210. 204. 197. 191. 190. 191. 229. 230. 242. 214. 193. 203. 137.\n",
      " 108. 190. 199. 200. 194. 199. 194. 195. 199. 200. 189. 187. 191. 189.\n",
      " 197. 198. 205. 200. 200. 208. 213. 215. 212. 213. 209. 202. 216. 137.\n",
      "  15.  55. 114. 157. 188. 207. 216. 220. 217. 219. 221. 242. 240. 243.\n",
      " 249. 253. 255. 255. 243. 232. 226. 222. 221. 213. 215. 198. 209.  62.\n",
      "  16.  11.   0.   0.   7.  40.  76. 108. 134. 142. 143. 145. 143. 123.\n",
      " 111.  92.  76.  61.  45.  35.  25.  25.  31.  32.  32.  12.   1.   0.\n",
      "   0.  11.  25.  26.  26.  22.  12.  20.  15.  15.  18.  17.  19.  27.\n",
      "  30.  36.  41.  49.  57.  66.  79.  84.  79.  83.  93.  80.  75.  45.\n",
      "   0.   0.   0.   0.   0.   9.  14.  17.  27.  34.  39.  39.  42.  44.\n",
      "  41.  41.  43.  48.  43.  30.  31.  35.  40.  37.  40.  37.  26.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 5:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   3.\n",
      "   1.   0.   0.   1.   1.   0.   0.   0.   0.  58.   0.  39.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   3.\n",
      "   0.   0.   0.   0.   0.   0.   0.  64. 109. 146. 192. 193.   7.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.  94.  38.  99. 209. 183. 229. 192. 142.  48.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.\n",
      "  41.  45. 158. 146. 164. 114.  51.   1.  53. 105.  42.  36.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  68.\n",
      "  44.  30.  59. 172. 146.   0.  22.   0.  13. 103. 111. 103.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   1.   0.  22.  61.\n",
      "  88. 152. 255.  71.   0.   0.   0.   0.  35.  85. 112. 201.  44.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  13.  62.\n",
      " 154.  62.   0.   0.   0.   0.   0.   0.  54.  99.  61. 106.  51.  19.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   9.   1.   0.   0.   1.   0.  79.  82.  47.  33.  58.  50.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.\n",
      "   1.   3.   9.   3.   0.   0.   1.   0. 100.  88.  48.  35.  70.  54.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   3.   0.   1.   0.   0. 111. 195. 119.  29.  58.  45.\n",
      "   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   3.   3.   0.   0.  91. 146. 171.  16.  93.  35.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  48.  45.   3.  79.  87.  99.   6.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   3.   0.   0. 119. 137.  33.  96.  77.  13.  45.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  32. 160. 164. 142. 116.  79.  82.  39.  39.   0.\n",
      "   0.   0.   0.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   3.\n",
      "   4.  10.   0.  41. 180. 142. 171.   1.   0.   0.  48.  73.  16.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.\n",
      "   3.   0.  27. 155. 114. 169.   0.   0.   0.   0.  47.  76.   6.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0. 155. 129. 160.   0.   0.   0.   0.   0.  45.  96.   0.   0.\n",
      "   0.   0.   0.   0.   1.   0.  16.  39.  64.   0.   0.   0.   0.   0.\n",
      "   0. 129. 151. 175.   0.   0.   0.   4.   4.   0.  48. 116.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  58.  87.  73.  10.   0.   0.   0.   0.\n",
      "  27. 187. 195.   0.   0.   0.   0.   3.   1.   0.  47. 146.   0.   0.\n",
      "   1.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 181. 225.  45.   0.   0.   0.   0.   0.   1.   0.  45. 186.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1. 183. 210.  90.   0.   0.   0. 126.\n",
      " 253. 142.   0.   0.   0.   0.   0.   0.   1.   0.  48. 203.   0.   0.\n",
      "  64.  58.  45.  27.  16.   9.   1. 175. 245. 204.  22.   0.  70. 236.\n",
      " 190.   6.   0.   0.   0.   0.   0.   0.   0.   0.  50. 196.   0.   0.\n",
      "  96. 128. 149. 163. 158. 140. 138. 146. 154. 108.  90. 148. 193. 177.\n",
      "  36.   0.   7.   0.   0.   0.   0.   0.   0.   0.  41. 125.   0.   0.\n",
      "   0.   0.   0.   0.  19.  47.  65.  93.  94. 125. 166. 180. 119.  29.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  32. 238.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 131.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 1:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.  53. 146. 127. 115. 111.\n",
      " 130. 129. 100. 147. 169. 190.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 117. 190. 188. 221. 234.\n",
      " 254. 236. 221. 205. 186. 222.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 127. 156. 175. 193. 195.\n",
      " 195. 202. 203. 187. 168. 228.  32.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 165. 186. 198. 209. 219.\n",
      " 198. 205. 211. 201. 189. 233.  94.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 185. 199. 210. 225. 207.\n",
      " 201. 207. 221. 210. 208. 236. 111.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 200. 175. 172. 215. 224.\n",
      " 216. 216. 223. 210. 198. 237. 152.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   7. 213. 156. 151. 171. 187.\n",
      " 215. 227. 212. 200. 178. 215. 177.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  25. 201. 136. 156. 178. 198.\n",
      " 213. 235. 168. 166. 163. 207. 178.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  42. 195. 134. 162. 171. 201.\n",
      "   1. 229. 198. 166. 154. 193. 173.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  50. 184. 134. 167. 184. 181.\n",
      "   0. 213. 190. 197. 179. 189. 179.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 175. 134. 169. 169. 211.\n",
      "   0. 196. 178. 153. 183. 196. 176.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  50. 173. 134. 167. 174. 223.\n",
      "   0. 161. 208. 140. 172. 198. 173.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 169. 125. 158. 187. 213.\n",
      "   0. 124. 219. 132. 149. 198. 176.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 168. 128. 150. 192. 197.\n",
      "   0.  82. 219. 152. 153. 177. 175.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  50. 174. 136. 144. 190. 185.\n",
      "   0.  29. 221. 155. 153. 184. 174.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  53. 175. 140. 161. 191. 143.\n",
      "   0.  13. 221. 154. 156. 184. 173.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  58. 184. 122. 166. 198. 115.\n",
      "   0.   0. 217. 158. 160. 180. 167.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  58. 204. 111. 172. 203.  79.\n",
      "   0.   0. 204. 164. 155. 188. 169.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 214. 138. 177. 209.  41.\n",
      "   0.   0. 186. 180. 152. 187. 168.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 214. 149. 177. 210.  23.\n",
      "   0.   0. 158. 199. 173. 192. 163.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 216. 159. 187. 204.   6.\n",
      "   0.   0. 136. 198. 189. 208. 165.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 212. 161. 197. 191.   0.\n",
      "   0.   0. 118. 192. 185. 214. 161.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  63. 201. 162. 207. 171.   0.\n",
      "   0.   0.  86. 197. 184. 214. 156.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  68. 197. 168. 213. 155.   0.\n",
      "   0.   0.  64. 196. 183. 219. 154.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  73. 193. 168. 215. 146.   0.\n",
      "   1.   0.  56. 190. 180. 205. 146.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  73. 176. 168. 204. 137.   0.\n",
      "   3.   0.  37. 186. 179. 204. 138.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  94. 197. 178. 212. 129.   0.\n",
      "   5.   0.  32. 193. 185. 210. 150.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 122. 126. 160.  65.   0.\n",
      "   3.   0.   8. 156. 173. 188. 107.   0.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 6:\n",
      "[  0.   0.   0.   2.   0.   2.   0.   0.   6.  36.  79.  24.   0.   0.\n",
      "   0.   0.   0.  31.  73.   1.   0.   0.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   2.   0.   0. 153. 160. 153. 176. 189. 188. 194.\n",
      " 145. 154. 149. 192. 179. 145. 161.  83.   0.   0.   2.   0.   0.   0.\n",
      "   0.   0.   0.   2.   0.   0. 135. 170. 144. 150. 147. 162. 187. 106.\n",
      "   1. 200. 177. 166. 146. 149. 151. 169. 113.   0.   3.   0.   0.   0.\n",
      "   0.   0.   0.   4.   0.  34. 179. 149. 151. 150. 145. 135. 169. 136.\n",
      "  86. 190. 156. 143. 146. 148. 146. 143. 157.   3.   0.   3.   0.   0.\n",
      "   0.   0.   0.   0.   0. 101. 177. 160. 152. 155. 150. 148. 144. 156.\n",
      " 163. 141. 154. 152. 150. 145. 147. 144. 163.  64.   0.   4.   0.   0.\n",
      "   0.   0.   0.   0.   0. 143. 178. 171. 154. 156. 149. 145. 149. 149.\n",
      " 145. 148. 147. 152. 148. 137. 152. 155. 162. 108.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 178. 174. 176. 163. 155. 144. 141. 146. 149.\n",
      " 140. 146. 143. 143. 139. 144. 150. 161. 163. 129.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   5. 166. 180. 174. 190. 161. 147. 146. 149. 149.\n",
      " 147. 147. 149. 147. 143. 144. 157. 179. 150. 163.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  30. 176. 178. 186. 208. 151. 149. 151. 154. 152.\n",
      " 152. 151. 152. 149. 141. 134. 194. 183. 155. 179.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  80. 181. 182. 196. 212. 147. 152. 150. 152. 151.\n",
      " 151. 151. 151. 147. 142. 131. 190. 198. 159. 160.  32.   0.   0.   0.\n",
      "   0.   0.   0.   0. 103. 182. 175. 206. 197. 152. 148. 150. 153. 154.\n",
      " 153. 150. 149. 142. 143. 136. 183. 224. 160. 161.  80.   0.   0.   0.\n",
      "   0.   0.   0.   0. 138. 187. 174. 225. 187. 150. 152. 152. 155. 154.\n",
      " 156. 154. 154. 147. 150. 131. 186. 227. 159. 162. 119.   0.   0.   0.\n",
      "   0.   0.   0.   0. 164. 195. 171. 235. 180. 154. 153. 153. 157. 157.\n",
      " 158. 152. 152. 147. 143. 137. 169. 232. 161. 173. 144.   0.   0.   0.\n",
      "   0.   0.   0.   0. 182. 200. 171. 231. 170. 154. 155. 157. 159. 159.\n",
      " 160. 157. 155. 144. 149. 142. 157. 232. 166. 187. 170.   0.   0.   0.\n",
      "   0.   0.   0.   0. 191. 201. 180. 251. 159. 157. 157. 157. 157. 159.\n",
      " 163. 152. 152. 147. 148. 148. 148. 226. 174. 193. 172.   0.   0.   0.\n",
      "   0.   0.   0.   7. 191. 209. 200. 203. 143. 166. 159. 157. 160. 162.\n",
      " 158. 156. 156. 143. 147. 154. 131. 215. 194. 195. 169.   5.   0.   0.\n",
      "   0.   0.   0.  24. 191. 212. 213. 212. 148. 166. 156. 155. 158. 161.\n",
      " 158. 156. 153. 145. 153. 148. 142. 204. 232. 184. 175.  27.   0.   0.\n",
      "   0.   0.   0.  40. 198. 213. 224. 193. 155. 162. 159. 157. 157. 164.\n",
      " 160. 160. 154. 145. 152. 154. 140. 161. 234. 178. 178.  38.   0.   0.\n",
      "   0.   0.   0.  46. 193. 224. 231. 122. 168. 163. 161. 159. 163. 171.\n",
      " 165. 169. 164. 152. 160. 155. 147. 124. 246. 190. 184.  49.   0.   0.\n",
      "   0.   0.   0.  42. 193. 225. 227. 115. 172. 150. 152. 150. 154. 152.\n",
      " 149. 156. 163. 152. 140. 139. 168.  87. 231. 195. 178.  63.   0.   0.\n",
      "   0.   0.   0.  52. 188. 217. 224. 107. 178. 174. 156. 165. 184. 162.\n",
      " 180. 174. 161. 171. 182. 166. 180.  86. 255. 186. 170.  72.   0.   0.\n",
      "   0.   0.   0.  58. 207. 232. 229. 120. 177. 181. 152. 160. 189. 183.\n",
      " 223. 167. 139. 156. 173. 179. 178.  62. 230. 146. 183.  78.   0.   0.\n",
      "   0.   0.   0.  70. 219. 232. 234. 175. 156. 185. 146. 164. 186. 186.\n",
      " 203. 155. 151. 160. 155. 198. 182. 131. 237. 164. 176. 101.   0.   0.\n",
      "   0.   0.   0.  91. 183. 198. 212. 151. 159. 178. 155. 159. 187. 195.\n",
      " 191. 152. 156. 156. 140. 210. 191. 137. 226. 203. 199. 100.   0.   0.\n",
      "   0.   0.   0.  98. 189. 192. 219. 150. 149. 166. 147. 148. 187. 211.\n",
      " 178. 152. 157. 148. 143. 188. 187. 125. 213. 200. 192.  96.   0.   0.\n",
      "   0.   0.   0.  87. 203. 171. 207. 171. 183. 172. 168. 165. 176. 199.\n",
      " 185. 161. 161. 161. 170. 187. 186. 155. 209. 195. 175.  63.   0.   0.\n",
      "   0.   0.   0.  44. 193. 217.  84.  80.  99.  79.  88. 125. 203. 171.\n",
      " 169. 199. 181. 186. 116. 118. 133. 114. 170. 221. 179.   4.   0.   0.\n",
      "   0.   0.   0.   0.  74. 133.   6.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  15. 160. 100.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 4:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   2.   0.   0.  12.  55.  98.  52.\n",
      "  45.  70.  47.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  39.  52.  93. 144.  83.\n",
      "  66.  86.  78.  48.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  35.  67.  36. 118. 151.  60.\n",
      "  28.  63.  44.  60.  52.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  51.  43.  29.  90. 211. 232.\n",
      " 157.  90.  22.  21.  53.   9.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.  36.  63.  99.  70.  63. 246. 241.\n",
      " 164. 116.  80. 110. 145. 117.  28.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  36.  66.  56.  63. 109.  55. 223. 255.\n",
      " 225. 110. 134. 105.  79.  76.  87.  49.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  52.  43.  59.  62.  39.  25.  44. 229.\n",
      " 228.  43.  40.  43.  62.  51.  56.  74.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   9.  58.  48.  49.  58.  60.  47.  16. 234.\n",
      " 180.  17.  59.  55.  64.  53.  60.  75.  40.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  29.  59.  40.  48.  40.  47.  56.  32.  78.\n",
      "  60.  41.  60.  49.  59.  49.  78.  72.  63.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  37.  68.  53.  37.  47.  45.  49.  22. 156.\n",
      "  93.  28.  56.  53.  62.  58. 103.  55.  79.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  52.  56.  66.  41.  41.  48.  49.  31.  89.\n",
      "  60.  37.  48.  56.  56.  63.  93.  49.  87.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  10.  66.  60.  99.  55.  39.  47.  47.  37.  76.\n",
      "  62.  39.  51.  60.  58.  72. 113.  47.  98.  20.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   9.  63.  71. 113.  48.  39.  47.  51.  35.  85.\n",
      "  67.  39.  63.  64.  59. 110. 140.  52.  87.  43.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  14.  53.  68. 106.  29.  48.  47.  55.  37.  74.\n",
      "  58.  45.  58.  62.  59. 121. 120.  37.  95.  52.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  24.  56.  67. 124.  36.  47.  48.  51.  39.  75.\n",
      "  76.  47.  51.  68.  71. 117. 140.  60.  76.  60.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  43.  62.  70. 114.  36.  43.  49.  49.  33.  75.\n",
      "  78.  39.  53.  66.  74.  98. 126.  62.  68.  89.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  49.  68. 107. 116.  12.  56.  44.  52.  33.  74.\n",
      "  75.  33.  66.  49. 101.  86. 103.  85.  86. 109.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  44.  71. 114.  97.  18.  66.  44.  52.  44.  67.\n",
      "  79.  47.  59.  33. 133.  91.  49. 121.  76. 110.  40.   0.   0.   0.\n",
      "   0.   0.   0.   0.  53.  68. 121.  37.  16.  55.  47.  52.  40.  66.\n",
      "  83.  47.  49.  49.  97.  91.  29. 102.  70. 109.  60.   0.   0.   0.\n",
      "   0.   0.   0.   0.  47.  56. 113.  32.  18.  55.  47.  59.  37.  60.\n",
      "  91.  33.  60.  62.  63.  90.   8. 114.  76.  80.  49.   0.   0.   0.\n",
      "   0.   0.   0.   0.  48.  59.  99.  20.  29.  52.  49.  55.  41.  64.\n",
      "  89.  35.  64.  48.  55. 111.  14.  59.  70.  67.  36.   0.   0.   0.\n",
      "   0.   0.   0.   0.  45.  63. 106.   0.  52.  52.  49.  48.  43.  58.\n",
      "  90.  49.  56.  59.  59.  99.  43.  21.  83.  76.  52.   0.   0.   0.\n",
      "   0.   0.   0.   0.  45.  63.  97.   0.  43.  48.  52.  48.  41.  55.\n",
      "  94.  43.  58.  70.  55.  85.  49.   5.  86.  75.  45.   0.   0.   0.\n",
      "   0.   0.   0.   0.  45.  70.  67.  14.  86.  41.  49.  51.  45.  58.\n",
      "  89.  36.  67.  63.  53.  80.  56.   1.  86.  71.  48.   0.   0.   0.\n",
      "   0.   0.   0.   0.  58.  99.  51.  45. 118.  39.  52.  48.  47.  55.\n",
      "  63.  55.  64.  53.  67.  70.  78.   0.  82.  91.  68.   0.   0.   0.\n",
      "   0.   0.   0.   0.  14.  25.  10.  29.  39.  49.  53.  44.  45.  48.\n",
      "  49.  64.  51.  62.  64.  58.  90.   6.   0.  13.   8.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  60.  60.  53.  53.  55.  55.  53.\n",
      "  66.  63.  62.  70.  70.  76.  93.  36.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   4.  53.  45.  53.  44.  43.  39.  43.\n",
      "  45.  41.  62.  49.  60.  56.  67.  22.   0.   2.   0.   0.   0.   0.] \n",
      "\n",
      "\n",
      "Example for class number 8:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   3.\n",
      "   1.   0.   1.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.  45.  40.  52.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  10.  96. 174. 128. 126. 114.  84. 100. 114.  77.  98.  77.  77.  93.\n",
      "  86.  84.  87. 107.  91.  94.  87.  87.  86.  91.  96. 103. 123.  26.\n",
      "  87. 144.  42. 103. 175. 167.  66. 117. 112. 133. 114. 121. 140. 131.\n",
      " 110. 149. 131. 110. 137. 128. 112. 105. 167. 186. 138.  98. 135.  63.\n",
      "  61. 140.  94. 156. 160. 145. 128.  65.  91. 205. 133. 165. 163.  75.\n",
      "  98. 160. 168. 140. 181. 124.  93. 131. 184. 181. 124. 119. 196.  38.\n",
      " 100. 168. 170. 126. 161. 177. 191.  63. 116. 170. 153. 154. 123.  75.\n",
      "  91. 131. 172. 168. 191. 124.  70. 170. 161. 117. 153. 205. 219.  47.\n",
      "  82. 189. 165. 161. 163. 198. 175.  98. 196. 144. 172. 126. 189. 156.\n",
      " 112. 184. 126. 189. 175. 174. 121. 172. 193. 182. 191. 189. 207.  52.\n",
      "  93. 156.  96. 168. 177. 158. 144. 121.  84. 149. 193. 193. 133.  73.\n",
      " 100. 110. 156. 230. 142.  70. 102. 126. 182. 200. 200. 158. 149.  29.\n",
      " 116. 138. 144. 182. 177. 172. 181. 191.  54. 145. 232.  91.  82. 165.\n",
      " 193.  96.  93. 221. 103.  79. 186. 202. 165. 189. 216. 167. 116.  42.\n",
      "  65. 145. 109. 119. 182. 198.  87. 110. 172. 165.  93.  68. 179. 198.\n",
      " 193. 153.  75. 112. 167. 191. 144. 105. 181. 219. 175. 172. 163.  59.\n",
      "  54. 218. 175.  86. 138. 156.  58. 177. 191. 221. 110.  58.  86. 168.\n",
      " 170. 103. 109. 119. 184. 189. 163.  56. 123. 198. 102. 198. 207.  61.\n",
      "  93. 168. 165. 128.  77.  82. 117. 131. 117. 158.  80. 149. 188. 112.\n",
      " 123. 163. 158. 110. 175. 163. 153. 131.  93.  86. 124. 202. 205.  89.\n",
      "  56. 177. 153.  89. 170. 128.  87. 211. 154. 182. 154. 175. 218. 124.\n",
      " 116. 253. 175. 133. 204. 191. 216. 138. 100. 174. 119. 151. 230.  51.\n",
      "  61. 116. 123. 154. 221. 144.  79. 177. 193. 193. 153. 109. 188. 145.\n",
      " 138. 209. 121. 130. 212. 211. 219. 109. 137. 255. 195. 114. 153.  72.\n",
      "  86. 102. 114. 138. 177. 130. 172. 200. 181. 172. 212. 149. 133.  96.\n",
      " 105. 100. 151. 170. 163. 184. 216. 175. 102. 204. 211. 116. 124.  73.\n",
      "  72. 114. 138.  86. 112. 147. 147. 140. 172. 165. 147. 153.  94. 112.\n",
      "  94. 117. 156. 151. 182. 165. 161. 177. 161. 165.  91. 130. 149.  49.\n",
      "  70. 121. 195. 175. 177. 193. 112.  80. 198. 154. 102. 109. 195. 189.\n",
      " 170. 181. 110.  58. 177. 209. 107.  61. 181. 207. 179. 207. 170.  63.\n",
      "  47. 112. 154. 161. 177. 119.  49.  98. 142. 107. 112. 119. 163. 186.\n",
      " 181. 188. 131. 102. 133. 158. 131.  94. 147. 184. 193. 205. 158.  43.\n",
      "  86. 200. 174. 161. 156. 209. 154. 109. 175. 170. 100. 161. 182. 174.\n",
      " 174. 198. 167. 112. 177. 165. 112. 142. 193. 179. 195. 202. 195. 100.\n",
      "  73. 130. 138. 182. 175. 154. 147. 119. 188. 184. 151. 145. 172. 172.\n",
      " 160. 131. 135. 137. 177. 188. 144. 147. 163. 181. 188. 163. 131.  61.\n",
      "  87. 109. 114. 205. 156. 100.  80. 140. 174. 184. 168.  87. 138. 168.\n",
      " 158. 105.  91. 121. 170. 182. 128. 140. 124. 109. 181.  96. 102.  93.\n",
      "  45.  98.  94. 121. 124. 142. 117. 116.  94. 170. 147. 110. 124. 123.\n",
      " 105. 110. 100.  94.  96. 119. 116. 112. 140. 102. 140. 123. 156.  70.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_CLASSES = 10\n",
    "is_shown = [False for x in range(NUMBER_OF_CLASSES)]\n",
    "printed = 0\n",
    "for i in range(len(train_labels)):\n",
    "    if(printed == NUMBER_OF_CLASSES):\n",
    "        break\n",
    "    if is_shown[train_labels[i]]:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Example for class number %d:\"% train_labels[i])\n",
    "        print(train_data[i], \"\\n\\n\")\n",
    "        is_shown[train_labels[i]] = True\n",
    "        printed += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- As drawn below, the frequency of the labels are equal in test labels and train data labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEWCAYAAADb3nSrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdw0lEQVR4nO3debwcVZ338c+XJCxRIMHEAFkISFBBWWIEGUdFomFxNLiAOAgRo9ER50FHZwTHZ3BE5sEZlUVGFCUScEEEWQbBEJFNhyVhhyAmxmASAokkgMga/D1/nNOhcu2+t3PvqZvb5Pt+vfrVVadO1e9U980vVXW6TikiMDOzvtlkQzfAzOzFwMnUzKwAJ1MzswKcTM3MCnAyNTMrwMnUzKwAJ1PrM0lXSprWy3UXS3pbm3VD0s69jNOrdSV9WdIfJT3Um7i28Ri8oRtgG4akJyqzQ4FngOfz/Mci4gftbisiDirZtoFC0jjgM8AOEbFiQ7fHBjYn041URLy0MS1pMfCRiPhF13qSBkfEmv5s2wAyDnikVSLdyD8b68Kn+bYOSftJWirpc/nU9nuShku6XNJKSavz9JjKOtdK+kie/pCkX0n6aq77e0ltHblK2lvSjZIelbRc0hmSNu1S7WBJi/Kp939J2qSy/ocl3Zfjzpa0Q4s4B0uaL+lPkpZJ+myTOm8D5gDbS3pC0jmSxufLBdMl/QH4ZU9xJb1d0m8kPZb357rKZ/VFSd+v1G1sf3Ce31rS2fmzWJYvOQxq53OWtI2k70l6MC+/JJffI+mdlXpD8me5VzvfkbXmZGrNbAtsA+wAzCD9nXwvz48DngLO6Gb9fYD7gRHAfwJnS1IbcZ8HPp3X2xeYDHyiS513A5OAicBU4MMAkqYCnwfeA4wEbgB+1CLO2aRLGVsCryEnxap8lH4Q8GBEvDQiPlRZ/Bbg1cAB3cWVNAL4KfCFvE+/A97YxufQcA6wBtgZ2AuYAnyksry7z/k80uWb3YCXA6fk8nOBD1a2cTCwPCJuX492WTMR4ddG/gIWA2/L0/sBzwKbd1N/T2B1Zf5a0mUCgA8BCyvLhgIBbNtT7CbLPgVcXJkP4MDK/CeAq/P0lcD0yrJNgCdJ1zsb6+6cp/8AfAzYqofPZT9gaWV+fN7OTpWylnGBo4CbKssELK18Vl8Evt9k+4OBUaTr2FtUln8AuKanzxnYDvgLMLzJPm0P/Kmx78CFwL9s6L/BF8PLR6bWzMqIeLoxI2mopG9LekDS48D1wLDGKWcTa3u+I+LJPPnSFnXXkrRLvoTwUI7zH6SjrqollekHSMkBUvI6LV8ieBRYRUpeo5uEei/piOyBfNq9b09t66YN3cXdvlo3UvaqrtudHYAhwPLKtr9NOspsaPU5jwVWRcTqrhuNiAeBXwPvlTSMdPTddmejteZkas10HUrsM8ArgX0iYivgzbm8nVP39XEm8BtgQo7z+SYxxlamxwEP5uklpFP3YZXXFhHxv12DRMTciJhKSkyXABesZzurn093cZdX25tPwavt/zPpiLJh2y7bfQYYUdnuVhGxWxvtWwJsk5NlM7NIp/qHAjdGxLI2tmk9cDK1dmxJuk76qKRtgBNqjPM48ISkVwH/0KTOP+cOsbHAscCPc/m3gOMl7QZrO28O7bqypE0lHSFp64h4Lsf7Sx/a3F3cnwG7SXpP7lT6P6ybMO8A3ixpnKStgeMbCyJiOXAV8DVJW0naRNIrJL2lpwblda8Evpk/qyGS3lypcgnpmvOxpGuoVoCTqbXjVGAL4I/ATcDPa4rzWeDvSdf0vsMLibLqUuBWUiL6GakziYi4GPgKcH6+RHAP6RS2mSOBxbnex4Ejetvg7uJGxB9JR38nA48AE0in2I115+R9vCvv0+VdNn8UsCkwH1hNur65XZtNOxJ4jnSkv4J0/bkR9yngImBHUgeZFaB8EdrM+oGka0mdTt/dwO34N2CXiPhgj5WtLf7RvtlGJl+qmU46erVCfJpvthGR9FFSB9WVEXH9hm7Pi4lP883MCvCRqZlZAS/Ka6YjRoyI8ePHb+hmmNmLzK233vrHiBjZbNmLMpmOHz+eefPmbehmmNmLjKQHWi3zab6ZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBdSaTCUNk3RhfgbOfZL2zc+mmSNpQX4fnutK0umSFkq6S9LEynam5foL1MtHCpuZ1anuI9PTgJ9HxKuAPYD7gONIj5qYAFyd5yENWzYhv2aQBgpuDMpwAul5N3sDJzQSsJnZQFFbMs2D3b6ZF8abfDYiHiU9BG1WrjYLOCRPTwXOjeQm0mMxtgMOAOZEROMxDHOAA+tqt5lZb9R5B9SOwErSo4L3IA1+eywwKo8EDukZNqPy9GjWfT7O0lzWqnwdkmaQjmgZN25cy0aNP+5nvdgVWHzyO3q1nuM5nuP1LV6n7Fudp/mDSY9GODMi9iI97+a4aoX8gLEiw1ZFxFkRMSkiJo0c2fTWWTOz2tSZTJeSHpN7c56/kJRcH86n7+T3FXn5MtZ92NiYXNaq3MxswKgtmUbEQ8ASSa/MRZNJz7K5DGj0yE8jPdOHXH5U7tV/A/BYvhwwG5iSHww2HJiSy8zMBoy6R436R+AHkjYFFgFHkxL4BZKmk557fliuewXpWeYLgSdzXSJilaQTgbm53pciYlXN7TYzWy+1JtOIuAOY1GTR5CZ1AzimxXZmAjOLNs7MrCDfAWVmVoCTqZlZAU6mZmYFOJmamRXgZGpmVoCTqZlZAU6mZmYFOJmamRXgZGpmVoCTqZlZAU6mZmYFOJmamRXgZGpmVoCTqZlZAU6mZmYFOJmamRXgZGpmVoCTqZlZAU6mZmYFOJmamRXgZGpmVoCTqZlZAU6mZmYFOJmamRXgZGpmVkCtyVTSYkl3S7pD0rxcto2kOZIW5PfhuVySTpe0UNJdkiZWtjMt118gaVqdbTYz643+ODJ9a0TsGRGT8vxxwNURMQG4Os8DHARMyK8ZwJmQki9wArAPsDdwQiMBm5kNFBviNH8qMCtPzwIOqZSfG8lNwDBJ2wEHAHMiYlVErAbmAAf2c5vNzLpVdzIN4CpJt0qakctGRcTyPP0QMCpPjwaWVNZdmstala9D0gxJ8yTNW7lyZcl9MDPr0eCat/+3EbFM0suBOZJ+U10YESEpSgSKiLOAswAmTZpUZJtmZu2q9cg0Ipbl9xXAxaRrng/n03fy+4pcfRkwtrL6mFzWqtzMbMCoLZlKeomkLRvTwBTgHuAyoNEjPw24NE9fBhyVe/XfADyWLwfMBqZIGp47nqbkMjOzAaPO0/xRwMWSGnF+GBE/lzQXuEDSdOAB4LBc/wrgYGAh8CRwNEBErJJ0IjA31/tSRKyqsd1mZuuttmQaEYuAPZqUPwJMblIewDEttjUTmFm6jWZmpfgOKDOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKqD2ZShok6XZJl+f5HSXdLGmhpB9L2jSXb5bnF+bl4yvbOD6X3y/pgLrbbGa2vvrjyPRY4L7K/FeAUyJiZ2A1MD2XTwdW5/JTcj0k7QocDuwGHAh8U9Kgfmi3mVnbak2mksYA7wC+m+cF7A9cmKvMAg7J01PzPHn55Fx/KnB+RDwTEb8HFgJ719luM7P1VfeR6anAvwB/yfMvAx6NiDV5fikwOk+PBpYA5OWP5fpry5uss5akGZLmSZq3cuXKwrthZta92pKppL8DVkTErXXFqIqIsyJiUkRMGjlyZH+ENDNba3CN234j8C5JBwObA1sBpwHDJA3OR59jgGW5/jJgLLBU0mBga+CRSnlDdR0zswGhtiPTiDg+IsZExHhSB9IvI+II4BrgfbnaNODSPH1Znicv/2VERC4/PPf27whMAG6pq91mZr1R55FpK58Dzpf0ZeB24OxcfjZwnqSFwCpSAiYi7pV0ATAfWAMcExHP93+zzcxa65dkGhHXAtfm6UU06Y2PiKeBQ1usfxJwUn0tNDPrm7ZO8yW9tu6GmJl1snavmX5T0i2SPiFp61pbZGbWgdpKphHxJuAIUq/6rZJ+KOnttbbMzKyDtN2bHxELgC+QOpDeApwu6TeS3lNX48zMOkW710x3l3QK6R77/YF3RsSr8/QpNbbPzKwjtNub/w3S/fWfj4inGoUR8aCkL9TSMjOzDtJuMn0H8FTj952SNgE2j4gnI+K82lpnZtYh2r1m+gtgi8r80FxmZma0n0w3j4gnGjN5emg9TTIz6zztJtM/S5rYmJH0OuCpbuqbmW1U2r1m+ingJ5IeBARsC7y/rkaZmXWatpJpRMyV9Crglbno/oh4rr5mmZl1lvUZ6OT1wPi8zkRJRMS5tbTKzKzDtJVMJZ0HvAK4A2gMfxeAk6mZGe0fmU4Cds2DNZuZWRft9ubfQ+p0MjOzJto9Mh0BzJd0C/BMozAi3lVLq8zMOky7yfSLdTbCzKzTtfvTqOsk7QBMiIhfSBoKDKq3aWZmnaPdIfg+ClwIfDsXjQYuqalNZmYdp90OqGOANwKPw9qBol9eV6PMzDpNu8n0mYh4tjEjaTDpd6ZmZkb7yfQ6SZ8HtsjPfvoJ8D/1NcvMrLO0m0yPA1YCdwMfA64gPQ/KzMxovzf/L8B38svMzLpotzf/95IWdX31sM7mkm6RdKekeyX9ey7fUdLNkhZK+rGkTXP5Znl+YV4+vrKt43P5/ZIO6MP+mpnVYn3uzW/YHDgU2KaHdZ4B9o+IJyQNAX4l6Urgn4BTIuJ8Sd8CpgNn5vfVEbGzpMOBrwDvl7QrcDiwG7A98AtJuzSeR2VmNhC0dWQaEY9UXssi4lTSQ/a6WycqjzoZkl9Bejz0hbl8FnBInp6a58nLJ0tSLj8/Ip6JiN8DC4G922m3mVl/aXcIvomV2U1IR6o9ritpEHArsDPw38DvgEcjYk2uspR0AwD5fQlARKyR9Bjwslx+U2Wz1XWqsWYAMwDGjRvXzm6ZmRXT7mn+1yrTa4DFwGE9rZRPxfeUNAy4GHjVeravbRFxFnAWwKRJk/wbWDPrV+325r+1L0Ei4lFJ1wD7AsMkDc5Hp2OAZbnaMmAssDTfFLA18EilvKG6jpnZgNDuaf4/dbc8Ir7eZJ2RwHM5kW4BvJ3UqXQN8D7gfGAacGle5bI8f2Ne/suICEmXAT+U9HVSB9QE4JZ22m1m1l/Wpzf/9aSEB/BOUkJb0M062wGz8nXTTYALIuJySfOB8yV9GbgdODvXPxs4T9JCYBWpB5+IuFfSBcB80iWGY9yTb2YDTbvJdAwwMSL+BCDpi8DPIuKDrVaIiLuAvZqUL6JJb3xEPE36yVWzbZ0EnNRmW83M+l27t5OOAp6tzD+by8zMjPaPTM8FbpF0cZ4/hBd+E2pmttFrtzf/pHz30pty0dERcXt9zTIz6yztnuYDDAUej4jTSD9f2rGmNpmZdZx2Bzo5AfgccHwuGgJ8v65GmZl1mnaPTN8NvAv4M0BEPAhsWVejzMw6TbvJ9NmICPKjSiS9pL4mmZl1nnaT6QWSvk26FfSjwC/wQNFmZmu1M/KTgB+TBil5HHgl8G8RMafmtpmZdYwek2m+P/6KiHgt4ARqZtZEu6f5t0l6fa0tMTPrYO3eAbUP8EFJi0k9+iIdtO5eV8PMzDpJt8lU0riI+APgh9iZmXWjpyPTS0ijRT0g6aKIeG8/tMnMrOP0dM1Ulemd6myImVkn6ymZRotpMzOr6Ok0fw9Jj5OOULfI0/BCB9RWtbbOzKxDdJtMI2JQfzXEzKyTrc8QfGZm1oKTqZlZAU6mZmYFOJmamRXgZGpmVoCTqZlZAU6mZmYFOJmamRVQWzKVNFbSNZLmS7pX0rG5fBtJcyQtyO/Dc7kknS5poaS7JE2sbGtarr9A0rS62mxm1lt1HpmuAT4TEbsCbwCOkbQrcBxwdURMAK7O8wAHARPyawZwJqTkC5xAGlN1b+CERgI2MxsoakumEbE8Im7L038C7gNGA1OBWbnaLOCQPD0VODeSm0gP79uONJbqnIhYFRGrSY9OObCudpuZ9Ua/XDOVNB7YC7gZGBURy/Oih4BReXo0sKSy2tJc1qq8a4wZkuZJmrdy5cqyO2Bm1oPak6mklwIXAZ+KiMeryyIiKDS0X0ScFRGTImLSyJEjS2zSzKxttSZTSUNIifQHEfHTXPxwPn0nv6/I5cuAsZXVx+SyVuVmZgNGnb35As4G7ouIr1cWXQY0euSnAZdWyo/KvfpvAB7LlwNmA1MkDc8dT1NymZnZgNHu00l7443AkcDdku7IZZ8HTgYukDQdeAA4LC+7AjgYWAg8CRwNEBGrJJ0IzM31vhQRq2pst5nZeqstmUbEr1j3GVJVk5vUD+CYFtuaCcws1zozs7J8B5SZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQG1JVNJMyWtkHRPpWwbSXMkLcjvw3O5JJ0uaaGkuyRNrKwzLddfIGlaXe01M+uLOo9MzwEO7FJ2HHB1REwArs7zAAcBE/JrBnAmpOQLnADsA+wNnNBIwGZmA0ltyTQirgdWdSmeCszK07OAQyrl50ZyEzBM0nbAAcCciFgVEauBOfx1gjYz2+D6+5rpqIhYnqcfAkbl6dHAkkq9pbmsVflfkTRD0jxJ81auXFm21WZmPdhgHVAREUAU3N5ZETEpIiaNHDmy1GbNzNrS38n04Xz6Tn5fkcuXAWMr9cbkslblZmYDSn8n08uARo/8NODSSvlRuVf/DcBj+XLAbGCKpOG542lKLjMzG1AG17VhST8C9gNGSFpK6pU/GbhA0nTgAeCwXP0K4GBgIfAkcDRARKySdCIwN9f7UkR07dQyM9vgakumEfGBFosmN6kbwDEttjMTmFmwaWZmxfkOKDOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwKcDI1MyvAydTMrAAnUzOzApxMzcwK6JhkKulASfdLWijpuA3dHjOzqo5IppIGAf8NHATsCnxA0q4btlVmZi/oiGQK7A0sjIhFEfEscD4wdQO3ycxsLUXEhm5DjyS9DzgwIj6S548E9omIT1bqzABm5NlXAvf3ItQI4I99bK7jOZ7jDexYfYm3Q0SMbLZgcN/aM3BExFnAWX3ZhqR5ETGpUJMcz/EcbwDGqitep5zmLwPGVubH5DIzswGhU5LpXGCCpB0lbQocDly2gdtkZrZWR5zmR8QaSZ8EZgODgJkRcW8Nofp0mcDxHM/xOiJWLfE6ogPKzGyg65TTfDOzAc3J1MysgI0ymUraQtJ1kgZJ+k9J90q6T9LpktSk/vmSJvQx1mRJd1ReT0s6pEn9r0ravzexusQbJGmcpKvyvs2XNL7meM9X9q9pB2HJeHl+K0lLJZ3Ron6vv7su8XaQdFvet3slfbzmeK+TdGOOdZek97eoX/L7+7mkRyVd3k39kvGmSVqQX9Na1C/1eQ6S9BVJ9+RX+c8zIja6F3AMcCzwN8CvSZ1ag4Abgf2a1H8L8J2+xOpStg2wChjapP4OwFV93bc8fS3w9jz90n6I90Qb9YvFy/OnAT8EzmhRv9ffXZe/lU2BzSqf5WJg+xrj7QJMyGXbA8uBYTV/f5OBdwKX1/395X8Di/L78Dw9vMbP8x3AHFKn+0tIvxDaquT+bZRHpsARwKVAAJuT/6EAQ4CHm9S/AXibpN78+qERq+p9wJUR8WTXyhHxAPAySdv2ItbaeHnsgsERMSdv94k647VbuWQ8Sa8DRgFXdVO/L9/d2ngR8WxEPJPLNqP1WV2peL+NiAUAEfEgsAL4qztvSn6eEXE18KfuKheMdwAwJyJWRcRqUqI7sEn9Ip8naUyP6yNiTUT8GbirWby+7N9Gl0zz71R3iojFEXEjcA3pf/3lwOyIuK/rOhHxF2AhsEdvY3VZdDjwo25WvQ144/rEahJvF+BRST+VdLuk/2qcGtcUD2BzSfMk3dTsEkbJeJI2Ab4GfLa7dXr73XWNl+fHSroLWAJ8JSe52uJVyvcm/Yf/uxarlvr+2lUi3mjS59iwNJeto+DneSdwoKShkkYAb2XdG4GqerV/G10yJd2T+yiApJ2BV5PuqBoN7C/pTS3WW0E63epVrAZJ2wGvJf1mtpXexOoabzDwJlKyeT2wE/ChGuNBum95EvD3wKmSXlFjvE8AV0TE0jbWK7J/EbEkInYHdgamSRpVZzxY+/dyHnB0Tiy1xmtTx8WLiKuAK4D/JR3I3Ag8XzLexphMnyKd2gO8G7gpnwI/AVwJ7Ntivc3zur2N1XAYcHFEPNfNer2J1TXeUuCOSCNtrQEuASbWGI+IWJbfF5Gu1+5VY7x9gU9KWgx8FThK0sk1xlsrH5HeQ/rPqrZ4krYCfgb8a0Tc1M16RfevDSXirc8t4qX+Pk+KiD0j4u2AgN+WjLfRJdN8fWaQpM2BPwBvkTRY0hDSxe77ACSdm0+vGnYh/QPqbayGD9DlFF/S/5P07r7EahJvLjBMUuM62/7A/LriSRouabO8/RGk06Ta4kXEERExLiLGk46+z42I43K8Pn93TfZvjKQt8vaHA39LHpmspnibAhfn/bqwWq+mv5eWaoo3G5iS/26GA1NyWV2f5yBJL8vb3x3YnXytvdT+bXTJNLuK9I/hQtJ1qLtJ11TujIj/yXV2Bx4EyKdzT0XEQ32IhdJPk8YC13Wp81rgoVxnCOk0cl4vYq2NFxHPk5LM1ZLuJv1P/J264pEul8yTdCfpOvTJETG/xnjdKfXdVeO9Grg57991wFcj4u4a4x0GvBn4kF74udmeuU4tn6ekG4CfAJOVfm52QF3xImIVcCLpP/25wJdyGdTzeQ4BbpA0n3Qr6QfzGRuU2r/e/uSgk1+k093zulm+FfCTyvyngel1xMp1Zlem3w2cWNe+vdjjlfzuBmI8f38Dd/961cAXwwv4MDCozbpHk35m1B+xDqXJ7wkdb8N8dx0Qz9/fANk/D3RiZlbAxnrN1MysKCdTM7MCnEzNzApwMrUBRdK2eaSg30m6VdIVknaRNF7Sev/2r82YX5TU7W2pks5Rekpuu9usrb02MHXEY0ts4yBJpB+qz4qIw3PZHqTBTJZ0t67ZhuYjUxtI3go8FxHfahRExJ0RcUO1Uj7qu0FpfNHbJP1NLt9O0vX5B+73SHpTvvPlnDx/t6RPd9cASR+VNFfSnZIukjS0svhtSgO5/FbS3+X6g5QGkZmrNO7ox5psczdJt+R23aU+jM9pA5ePTG0geQ1waxv1VpDGaX06J6YfAY0BVmZHxElKI2QNBfYERkfEawAkDeth2z+NiO/kul8GpgPfyMvGA3sDrwCuURoo5yjgsYh4fb6d9teSriIN79jwceC0iPhBvk201ehd1sGcTK0TDQHOyLdXPk+6lxrSbYkz8y2Bl0TEHZIWATtJ+gZp0JDuxj4FeE1OosNIg0BXR/e6INLITQvydl9Fuqd898r11K2BCaw7iMaNwL9KGkNK1gt6s9M2sPk03waSe4HXtVHv06RBvPcgHZFuChAR15PuZ18GnCPpqEiDXexBGsXq48B3e9j2OcAnI+K1wL+z7qhKXe9wCdKYB/8YaTSiPSNix0jDvb1QKeKHwLtIIxFdoT489sMGLidTG0h+CWwmaUajQNLu+usxZrcGluejxCPJp82SdgAezqfp3wUm5hGsNomIi4Av0HoYwoYtgeX56PaILssOlbSJ0jitO5FGjZoN/EOuT/7lwUuqK0naCVgUEaeTRn3fvZ0PwzqLT/NtwIiIyEOhnSrpc8DTpGctfapL1W8CF0k6Cvg58Odcvh/wz5KeA54gXc8cDXxPaWR+gON7aMb/BW4GVub3LSvL/gDcQhqM4+P5mu13SddSb8u/RlgJHNJlm4cBR+Z2PQT8Rw9tsA7ke/PNzArwab6ZWQFOpmZmBTiZmpkV4GRqZlaAk6mZWQFOpmZmBTiZmpkV8P8BeB/M/hwHNjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mtplot\n",
    "import pandas as pd\n",
    "\n",
    "train_lab = pd.read_csv(\"./Fashion-MNIST/trainLabels.csv\", dtype=int)\n",
    "test_lab = pd.read_csv(\"./Fashion-MNIST/testLabels.csv\", dtype=int)\n",
    "train_lab.value_counts().plot(kind='bar', figsize=(5, 4), rot=0)\n",
    "mtplot.title(\"Train labels frequency\");\n",
    "mtplot.xlabel(\"Class labels\")\n",
    "mtplot.ylabel(\"Frequency\")\n",
    "mtplot.show()\n",
    "test_lab.value_counts().plot(kind='bar', figsize=(5, 4), rot=0)\n",
    "mtplot.title(\"Test labels frequency\");\n",
    "mtplot.xlabel(\"Class labels\")\n",
    "mtplot.ylabel(\"Frequency\")\n",
    "mtplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- The process of normalizing train data has been done in the data_processor() function. It scales the values to the (0, 1) range because working with big values such as 220 or 250 causes overflow in neural network calculations. The advantage of using this function is to avoid overflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2: Completing missing codes\n",
    "This part has been done and the complete code sections and their sample results have been placed at the top of this page.\n",
    "\n",
    "\n",
    "### Level 3: Data Classification\n",
    "\n",
    "#### Step 1: \n",
    "The sample output of the neural network which has been printed above, is the result of running the network with learning_rate = 0.0001, number_of_epochs = 30, and batch_size = 32, these values where the most efficient ones.\n",
    "\n",
    "#### Step 2: In the following sections, learning rate value is changed to 0.00001 and 0.001\n",
    "Changing Learning rate from 0.0001 to 0.00001: As the learning is too slow, the first epochs have not been classifiend accurately but after those first ones, the accuracy of the network's classification becomes reasonable but still it is below 70%. So 0.00001 is not appropriate for learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.10845\tAverage Loss: 0.2317605788915158\n",
      "\tTest: Average Accuracy: 0.10473242811501597\tAverage Loss: 0.2270036975999074\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.1169\tAverage Loss: 0.2256467098117353\n",
      "\tTest: Average Accuracy: 0.11331869009584665\tAverage Loss: 0.2238369516334139\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.13051666666666667\tAverage Loss: 0.22040215673622568\n",
      "\tTest: Average Accuracy: 0.10912539936102236\tAverage Loss: 0.21607749593640155\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.21553333333333333\tAverage Loss: 0.20839589322941776\n",
      "\tTest: Average Accuracy: 0.26677316293929715\tAverage Loss: 0.19968989244836133\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.3287833333333333\tAverage Loss: 0.18911493837022678\n",
      "\tTest: Average Accuracy: 0.35493210862619806\tAverage Loss: 0.17909305956751564\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.38838333333333336\tAverage Loss: 0.16980197757874052\n",
      "\tTest: Average Accuracy: 0.4326078274760383\tAverage Loss: 0.16194418706470173\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.45245\tAverage Loss: 0.1549086865668189\n",
      "\tTest: Average Accuracy: 0.472444089456869\tAverage Loss: 0.14939704684408311\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.4739\tAverage Loss: 0.14441900558759457\n",
      "\tTest: Average Accuracy: 0.4665535143769968\tAverage Loss: 0.14113062319284236\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.49088333333333334\tAverage Loss: 0.13689854080801833\n",
      "\tTest: Average Accuracy: 0.481629392971246\tAverage Loss: 0.13448648808267216\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.5168833333333334\tAverage Loss: 0.1306475897133311\n",
      "\tTest: Average Accuracy: 0.5343450479233227\tAverage Loss: 0.1289220674221143\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.55545\tAverage Loss: 0.1251787239091317\n",
      "\tTest: Average Accuracy: 0.5629992012779552\tAverage Loss: 0.12401153261344218\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.5869\tAverage Loss: 0.12019944603928069\n",
      "\tTest: Average Accuracy: 0.5904552715654952\tAverage Loss: 0.11913850941122285\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.6082833333333333\tAverage Loss: 0.11557268154952274\n",
      "\tTest: Average Accuracy: 0.6119209265175719\tAverage Loss: 0.11489789982470608\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.6249\tAverage Loss: 0.11132480708292754\n",
      "\tTest: Average Accuracy: 0.6261980830670927\tAverage Loss: 0.11067158085006268\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.6354166666666666\tAverage Loss: 0.10713332078749324\n",
      "\tTest: Average Accuracy: 0.636082268370607\tAverage Loss: 0.10654060052811114\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.6439\tAverage Loss: 0.10314732638130127\n",
      "\tTest: Average Accuracy: 0.639576677316294\tAverage Loss: 0.10261496879747185\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.6493166666666667\tAverage Loss: 0.09949918461077693\n",
      "\tTest: Average Accuracy: 0.6463658146964856\tAverage Loss: 0.09924633064141584\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.65485\tAverage Loss: 0.09625497075896662\n",
      "\tTest: Average Accuracy: 0.6530551118210862\tAverage Loss: 0.09597544558344143\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.6592166666666667\tAverage Loss: 0.09340728841168627\n",
      "\tTest: Average Accuracy: 0.6592452076677316\tAverage Loss: 0.0934772872739562\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.66375\tAverage Loss: 0.09098571391659345\n",
      "\tTest: Average Accuracy: 0.6630391373801917\tAverage Loss: 0.09123874754789896\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.6679666666666667\tAverage Loss: 0.08888082730167557\n",
      "\tTest: Average Accuracy: 0.6638378594249201\tAverage Loss: 0.08909311460779068\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.6711166666666667\tAverage Loss: 0.0870270864917589\n",
      "\tTest: Average Accuracy: 0.669029552715655\tAverage Loss: 0.08749033194180392\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.67385\tAverage Loss: 0.08541385722483574\n",
      "\tTest: Average Accuracy: 0.672923322683706\tAverage Loss: 0.08589241410895186\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.6775333333333333\tAverage Loss: 0.08398148845449738\n",
      "\tTest: Average Accuracy: 0.6741214057507987\tAverage Loss: 0.08461272671188048\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.6805666666666667\tAverage Loss: 0.08270378207848122\n",
      "\tTest: Average Accuracy: 0.6775159744408946\tAverage Loss: 0.08345160013139839\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.6838\tAverage Loss: 0.08154969509731713\n",
      "\tTest: Average Accuracy: 0.6788138977635783\tAverage Loss: 0.08242504941337184\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.68595\tAverage Loss: 0.08049594180777027\n",
      "\tTest: Average Accuracy: 0.6837060702875399\tAverage Loss: 0.08137967698500784\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.6891\tAverage Loss: 0.07953144345978233\n",
      "\tTest: Average Accuracy: 0.6839057507987221\tAverage Loss: 0.0804528084988928\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.6912\tAverage Loss: 0.07863062191939231\n",
      "\tTest: Average Accuracy: 0.6886980830670927\tAverage Loss: 0.07959041297098322\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.6942833333333334\tAverage Loss: 0.0778049672901893\n",
      "\tTest: Average Accuracy: 0.6897963258785943\tAverage Loss: 0.0787037940409327\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.00001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Changing Learning rate from 0.0001 to 0.001: Based on the results printed below, it seems that 0.001 is doing better than 0.0001 since we've got better accuracy.\n",
    "\n",
    "##### So the Learning Rate value will be changed to 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.6805333333333333\tAverage Loss: 0.08921194554182095\n",
      "\tTest: Average Accuracy: 0.8052116613418531\tAverage Loss: 0.05706358157845523\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8239666666666666\tAverage Loss: 0.05085467006566701\n",
      "\tTest: Average Accuracy: 0.8226837060702875\tAverage Loss: 0.05094052001076687\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8417833333333333\tAverage Loss: 0.045755845069567244\n",
      "\tTest: Average Accuracy: 0.8398562300319489\tAverage Loss: 0.04634198408420854\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8504\tAverage Loss: 0.043316722885130145\n",
      "\tTest: Average Accuracy: 0.8398562300319489\tAverage Loss: 0.04588548163258225\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8540333333333333\tAverage Loss: 0.04171548629280199\n",
      "\tTest: Average Accuracy: 0.8357627795527156\tAverage Loss: 0.048614660011852405\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8576\tAverage Loss: 0.04059828998684979\n",
      "\tTest: Average Accuracy: 0.84375\tAverage Loss: 0.04566018272006286\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.86035\tAverage Loss: 0.03982250285298517\n",
      "\tTest: Average Accuracy: 0.8489416932907349\tAverage Loss: 0.042643596309152744\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8646\tAverage Loss: 0.038958940838437386\n",
      "\tTest: Average Accuracy: 0.8423522364217252\tAverage Loss: 0.04536349044594005\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.86485\tAverage Loss: 0.038325981798063236\n",
      "\tTest: Average Accuracy: 0.8520367412140575\tAverage Loss: 0.042196759244673816\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8666\tAverage Loss: 0.03785501888748281\n",
      "\tTest: Average Accuracy: 0.8447484025559105\tAverage Loss: 0.04386495748757107\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8675\tAverage Loss: 0.037324536228246386\n",
      "\tTest: Average Accuracy: 0.8374600638977636\tAverage Loss: 0.04650970181055424\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8689833333333333\tAverage Loss: 0.03691252241599194\n",
      "\tTest: Average Accuracy: 0.8523362619808307\tAverage Loss: 0.040753142106965075\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.87115\tAverage Loss: 0.036524356651712026\n",
      "\tTest: Average Accuracy: 0.8495407348242812\tAverage Loss: 0.042539058480047943\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8714333333333333\tAverage Loss: 0.036256935003612274\n",
      "\tTest: Average Accuracy: 0.8519369009584664\tAverage Loss: 0.041401036700821264\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8720833333333333\tAverage Loss: 0.036110411754185626\n",
      "\tTest: Average Accuracy: 0.8540335463258786\tAverage Loss: 0.04183610441700129\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8724833333333334\tAverage Loss: 0.03571574844133328\n",
      "\tTest: Average Accuracy: 0.8476437699680511\tAverage Loss: 0.04283412434632155\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8741333333333333\tAverage Loss: 0.03538640774630815\n",
      "\tTest: Average Accuracy: 0.8532348242811502\tAverage Loss: 0.041250741512498135\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.87495\tAverage Loss: 0.03514858948741844\n",
      "\tTest: Average Accuracy: 0.8545327476038339\tAverage Loss: 0.042021614527035324\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8751333333333333\tAverage Loss: 0.03496826318177135\n",
      "\tTest: Average Accuracy: 0.8540335463258786\tAverage Loss: 0.04070374203033867\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.87685\tAverage Loss: 0.03481706925089762\n",
      "\tTest: Average Accuracy: 0.8580271565495208\tAverage Loss: 0.04026043394286354\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8755833333333334\tAverage Loss: 0.03454823453320674\n",
      "\tTest: Average Accuracy: 0.8568290734824281\tAverage Loss: 0.04159920451111631\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8759166666666667\tAverage Loss: 0.03431651493424369\n",
      "\tTest: Average Accuracy: 0.8577276357827476\tAverage Loss: 0.040130806192681015\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8772\tAverage Loss: 0.03442791853766043\n",
      "\tTest: Average Accuracy: 0.8533346645367412\tAverage Loss: 0.04223411912461067\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.87805\tAverage Loss: 0.03408397736044942\n",
      "\tTest: Average Accuracy: 0.8554313099041534\tAverage Loss: 0.041632502433755915\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8787333333333334\tAverage Loss: 0.03398530960805373\n",
      "\tTest: Average Accuracy: 0.8514376996805112\tAverage Loss: 0.04318409128782057\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8786\tAverage Loss: 0.03386157077873936\n",
      "\tTest: Average Accuracy: 0.8575279552715654\tAverage Loss: 0.04206843033228573\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8788\tAverage Loss: 0.03376061588535055\n",
      "\tTest: Average Accuracy: 0.8512380191693291\tAverage Loss: 0.04250203185607136\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.88035\tAverage Loss: 0.03350021967288608\n",
      "\tTest: Average Accuracy: 0.8597244408945687\tAverage Loss: 0.04044270974778329\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.87985\tAverage Loss: 0.033354260056513985\n",
      "\tTest: Average Accuracy: 0.8562300319488818\tAverage Loss: 0.04057122511128468\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8809\tAverage Loss: 0.033126255762027275\n",
      "\tTest: Average Accuracy: 0.8578274760383386\tAverage Loss: 0.04010300645270929\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Changing the activation function of first layer\n",
    "The first sample result belongs to Relu() function. Sigmoid and LeakyRelu() are tested in following code sections.\n",
    "\n",
    "-- Testing LeakyRelu() activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.68935\tAverage Loss: 0.08729812871050333\n",
      "\tTest: Average Accuracy: 0.7924321086261981\tAverage Loss: 0.061291102029256424\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8260666666666666\tAverage Loss: 0.05006605019322643\n",
      "\tTest: Average Accuracy: 0.8211861022364217\tAverage Loss: 0.05069155857774517\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8412833333333334\tAverage Loss: 0.04547918101048267\n",
      "\tTest: Average Accuracy: 0.8185902555910544\tAverage Loss: 0.04938487796791863\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8496333333333334\tAverage Loss: 0.043057794193646734\n",
      "\tTest: Average Accuracy: 0.8256789137380192\tAverage Loss: 0.04816736406621305\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8527333333333333\tAverage Loss: 0.041646556985964804\n",
      "\tTest: Average Accuracy: 0.8444488817891374\tAverage Loss: 0.04388503798981531\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.85695\tAverage Loss: 0.04040554001676133\n",
      "\tTest: Average Accuracy: 0.8469448881789138\tAverage Loss: 0.043132688258249535\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8597\tAverage Loss: 0.039548409886874976\n",
      "\tTest: Average Accuracy: 0.8505391373801917\tAverage Loss: 0.042289532213236836\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8637833333333333\tAverage Loss: 0.03870883278906611\n",
      "\tTest: Average Accuracy: 0.8515375399361023\tAverage Loss: 0.04158542523075549\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8657833333333333\tAverage Loss: 0.03810185546595653\n",
      "\tTest: Average Accuracy: 0.8503394568690096\tAverage Loss: 0.041490517540229685\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.86695\tAverage Loss: 0.03757471607556636\n",
      "\tTest: Average Accuracy: 0.8505391373801917\tAverage Loss: 0.04228290367855345\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8685833333333334\tAverage Loss: 0.03710248422663176\n",
      "\tTest: Average Accuracy: 0.8447484025559105\tAverage Loss: 0.043422496287006125\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.86995\tAverage Loss: 0.036602603370464074\n",
      "\tTest: Average Accuracy: 0.8433506389776357\tAverage Loss: 0.04328221576290757\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8701666666666666\tAverage Loss: 0.036245323765824886\n",
      "\tTest: Average Accuracy: 0.8441493610223643\tAverage Loss: 0.044332749044483755\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.87325\tAverage Loss: 0.035827254876581026\n",
      "\tTest: Average Accuracy: 0.8525359424920128\tAverage Loss: 0.042646309078479536\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.87285\tAverage Loss: 0.035652488592236346\n",
      "\tTest: Average Accuracy: 0.8527356230031949\tAverage Loss: 0.0419555622964549\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8725333333333334\tAverage Loss: 0.035282049030411065\n",
      "\tTest: Average Accuracy: 0.8558306709265175\tAverage Loss: 0.04040858470377734\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8749666666666667\tAverage Loss: 0.03495429978579091\n",
      "\tTest: Average Accuracy: 0.8441493610223643\tAverage Loss: 0.0433358410691974\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8758666666666667\tAverage Loss: 0.03459069680598858\n",
      "\tTest: Average Accuracy: 0.8597244408945687\tAverage Loss: 0.04006470850307195\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8766333333333334\tAverage Loss: 0.03439454489644412\n",
      "\tTest: Average Accuracy: 0.8578274760383386\tAverage Loss: 0.04039045298710254\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8768666666666667\tAverage Loss: 0.034120309548236534\n",
      "\tTest: Average Accuracy: 0.8590255591054313\tAverage Loss: 0.04012781243746677\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.877\tAverage Loss: 0.034020015640552084\n",
      "\tTest: Average Accuracy: 0.8484424920127795\tAverage Loss: 0.04232689432143875\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8805\tAverage Loss: 0.033633505640828794\n",
      "\tTest: Average Accuracy: 0.8631190095846646\tAverage Loss: 0.03931095546949274\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8807\tAverage Loss: 0.0335566207293634\n",
      "\tTest: Average Accuracy: 0.8592252396166135\tAverage Loss: 0.03956474844801282\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8813166666666666\tAverage Loss: 0.033188127435004496\n",
      "\tTest: Average Accuracy: 0.8614217252396166\tAverage Loss: 0.03956055482293006\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8806833333333334\tAverage Loss: 0.033199332533415664\n",
      "\tTest: Average Accuracy: 0.8605231629392971\tAverage Loss: 0.039959008499722816\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.88255\tAverage Loss: 0.03304146122207984\n",
      "\tTest: Average Accuracy: 0.8495407348242812\tAverage Loss: 0.042526482106265216\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.88155\tAverage Loss: 0.03287933211922874\n",
      "\tTest: Average Accuracy: 0.8617212460063898\tAverage Loss: 0.03978124447821581\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8818833333333334\tAverage Loss: 0.03271744305828274\n",
      "\tTest: Average Accuracy: 0.8608226837060703\tAverage Loss: 0.04039850843002453\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8826666666666667\tAverage Loss: 0.03269842247038561\n",
      "\tTest: Average Accuracy: 0.8593250798722045\tAverage Loss: 0.03967570948605178\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8833666666666666\tAverage Loss: 0.03258317890046178\n",
      "\tTest: Average Accuracy: 0.8559305111821086\tAverage Loss: 0.04077650146092164\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Testing Sigmoid() activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.12446666666666667\tAverage Loss: 0.2294295612335246\n",
      "\tTest: Average Accuracy: 0.20996405750798722\tAverage Loss: 0.21503369064450392\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.34701666666666664\tAverage Loss: 0.1760961428152356\n",
      "\tTest: Average Accuracy: 0.5208666134185304\tAverage Loss: 0.1444681616868189\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.54195\tAverage Loss: 0.12423503964541967\n",
      "\tTest: Average Accuracy: 0.6207068690095847\tAverage Loss: 0.10930745540160194\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.6877833333333333\tAverage Loss: 0.09577685438270736\n",
      "\tTest: Average Accuracy: 0.7112619808306709\tAverage Loss: 0.08647526293208087\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7341833333333333\tAverage Loss: 0.07910656957805963\n",
      "\tTest: Average Accuracy: 0.733326677316294\tAverage Loss: 0.07511026260635931\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7495333333333334\tAverage Loss: 0.06987477312199693\n",
      "\tTest: Average Accuracy: 0.7496006389776357\tAverage Loss: 0.06828833826051858\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.7670666666666667\tAverage Loss: 0.06391323872421119\n",
      "\tTest: Average Accuracy: 0.7674720447284346\tAverage Loss: 0.06300421113503456\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.7961333333333334\tAverage Loss: 0.05894053375450424\n",
      "\tTest: Average Accuracy: 0.7999201277955271\tAverage Loss: 0.058675544118033315\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8188\tAverage Loss: 0.05451395067542395\n",
      "\tTest: Average Accuracy: 0.8133985623003195\tAverage Loss: 0.055522752439083986\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8307333333333333\tAverage Loss: 0.051025096257253245\n",
      "\tTest: Average Accuracy: 0.819888178913738\tAverage Loss: 0.0528046932021703\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.83765\tAverage Loss: 0.048571387453217006\n",
      "\tTest: Average Accuracy: 0.8269768370607029\tAverage Loss: 0.05087592157597271\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.84145\tAverage Loss: 0.04690078393601339\n",
      "\tTest: Average Accuracy: 0.8302715654952076\tAverage Loss: 0.04927166803990212\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8448833333333333\tAverage Loss: 0.04561297521549462\n",
      "\tTest: Average Accuracy: 0.8331669329073482\tAverage Loss: 0.04876272553811048\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8473166666666667\tAverage Loss: 0.04455934587751236\n",
      "\tTest: Average Accuracy: 0.8343650159744409\tAverage Loss: 0.04786167353236262\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8494333333333334\tAverage Loss: 0.04367568524814037\n",
      "\tTest: Average Accuracy: 0.836361821086262\tAverage Loss: 0.04724833932671174\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8519333333333333\tAverage Loss: 0.042978546287712555\n",
      "\tTest: Average Accuracy: 0.8386581469648562\tAverage Loss: 0.046614398002779056\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.85395\tAverage Loss: 0.04234695540666053\n",
      "\tTest: Average Accuracy: 0.8406549520766773\tAverage Loss: 0.045930309038710204\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8548666666666667\tAverage Loss: 0.04172205462750939\n",
      "\tTest: Average Accuracy: 0.8373602236421726\tAverage Loss: 0.046028999265688576\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8586\tAverage Loss: 0.04124120190349904\n",
      "\tTest: Average Accuracy: 0.8409544728434505\tAverage Loss: 0.04572675972080425\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8587166666666667\tAverage Loss: 0.04085175698587963\n",
      "\tTest: Average Accuracy: 0.8412539936102237\tAverage Loss: 0.04571337731603801\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8612333333333333\tAverage Loss: 0.04039348669477702\n",
      "\tTest: Average Accuracy: 0.8438498402555911\tAverage Loss: 0.04531145247498762\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8613333333333333\tAverage Loss: 0.04008952678571054\n",
      "\tTest: Average Accuracy: 0.8429512779552716\tAverage Loss: 0.04507242155799324\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.86275\tAverage Loss: 0.039775475773034925\n",
      "\tTest: Average Accuracy: 0.8443490415335463\tAverage Loss: 0.04450064238740548\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8628\tAverage Loss: 0.039438326353536016\n",
      "\tTest: Average Accuracy: 0.8458466453674122\tAverage Loss: 0.044290863639811065\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8647\tAverage Loss: 0.039140676419580474\n",
      "\tTest: Average Accuracy: 0.8466453674121406\tAverage Loss: 0.044080998928587946\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8660666666666667\tAverage Loss: 0.03890626831570808\n",
      "\tTest: Average Accuracy: 0.8443490415335463\tAverage Loss: 0.04420331921411787\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8654833333333334\tAverage Loss: 0.03871751696040556\n",
      "\tTest: Average Accuracy: 0.8488418530351438\tAverage Loss: 0.04362582340482715\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8665666666666667\tAverage Loss: 0.03849775187863549\n",
      "\tTest: Average Accuracy: 0.8506389776357828\tAverage Loss: 0.04378622246410863\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.86735\tAverage Loss: 0.038311960759157056\n",
      "\tTest: Average Accuracy: 0.8448482428115016\tAverage Loss: 0.04447208456404539\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.86875\tAverage Loss: 0.03804495991210475\n",
      "\tTest: Average Accuracy: 0.8486421725239617\tAverage Loss: 0.043477594470147034\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I) The advantage of Leaky ReLU over normal ReLU: normal ReLU return a constant 0 value for negative inputs which are known as dead values and may block the learning process in some networks since in the back-propagation phase (which updates the weights), the derivative for negative values is 0 and this, stops the learning progress if we don't handle the negative values. \n",
    "\n",
    "II) The network which uses sigmoid function has the maximum accuracy of 83% which is a bit less than other activation functions. One major benefit of ReLU (and LeakyReLU) over Sigmoid is the reduced likelihood of the gradient to vanish. When a (input of activation function) is positive, the gradient has a constant value. In contrast, the gradient of sigmoids becomes increasingly small as the absolute value of x increases. The constant gradient of ReLUs results in faster learning. The other benefit of ReLUs is sparsity which arises when a is negative. The more such units that exist in a layer the more sparse the resulting representation. Sigmoids on the other hand are always likely to generate some non-zero value resulting in dense representations, since sparse representations seem to be more beneficial than dense representations.\n",
    "\n",
    "##### According to the printed accuracies, LeakyReLU and ReLU have done a bit better than Sigmoid. Thus LeakyReLU is chosen for the chosen activation function in the following code sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Changing the batch size\n",
    "In the first sample result, each batch contains 32 rows of data. It will be changed and tested in the following sections. Large batch size means the model makes very large gradient updates. The size of the update depends heavily on which particular samples are drawn from the dataset. On the other hand using small batch size means the model makes updates that are all about the same size. The size of the update only weakly depends on which particular samples are drawn from the dataset.\n",
    "\n",
    "-- Testing BATCH_SIZE=128 on the network: As it's obvious, we can not achieve a high accuracy using larger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.4337519989339019\tAverage Loss: 0.17017457272804917\n",
      "\tTest: Average Accuracy: 0.5851463607594937\tAverage Loss: 0.12416653896999602\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.6409470504619759\tAverage Loss: 0.10088967807335435\n",
      "\tTest: Average Accuracy: 0.6782041139240507\tAverage Loss: 0.08932963792640902\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6916866560056859\tAverage Loss: 0.08584120212959473\n",
      "\tTest: Average Accuracy: 0.7018393987341772\tAverage Loss: 0.08532283785408169\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7182336087420043\tAverage Loss: 0.08056192233203381\n",
      "\tTest: Average Accuracy: 0.7224090189873418\tAverage Loss: 0.08265192963163151\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7449360341151386\tAverage Loss: 0.07554799677249571\n",
      "\tTest: Average Accuracy: 0.7586036392405063\tAverage Loss: 0.07292007242365424\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7718716684434968\tAverage Loss: 0.07000996179397864\n",
      "\tTest: Average Accuracy: 0.7666139240506329\tAverage Loss: 0.07072139930383108\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.7872690120824449\tAverage Loss: 0.06601356067666617\n",
      "\tTest: Average Accuracy: 0.7791732594936709\tAverage Loss: 0.070038892210039\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.7872912224591329\tAverage Loss: 0.06270202547547028\n",
      "\tTest: Average Accuracy: 0.7697784810126582\tAverage Loss: 0.06587776432496402\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.7901174928926795\tAverage Loss: 0.06132532299100111\n",
      "\tTest: Average Accuracy: 0.7615704113924051\tAverage Loss: 0.06800400308254718\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.7904284381663113\tAverage Loss: 0.061840881981218884\n",
      "\tTest: Average Accuracy: 0.7962816455696202\tAverage Loss: 0.058309766453557905\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.7957866915422885\tAverage Loss: 0.05995061279642356\n",
      "\tTest: Average Accuracy: 0.8006329113924051\tAverage Loss: 0.05755714924594369\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.7993459044065387\tAverage Loss: 0.06047672168349298\n",
      "\tTest: Average Accuracy: 0.8004351265822784\tAverage Loss: 0.060358279958833895\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.7997401385927505\tAverage Loss: 0.06242591587244869\n",
      "\tTest: Average Accuracy: 0.8078520569620253\tAverage Loss: 0.05891105718177533\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8018945451314855\tAverage Loss: 0.06287562824669139\n",
      "\tTest: Average Accuracy: 0.6704905063291139\tAverage Loss: 0.2382451327679301\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8006452114427861\tAverage Loss: 0.06303957855171105\n",
      "\tTest: Average Accuracy: 0.7980617088607594\tAverage Loss: 0.06561073326612749\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8063477256574271\tAverage Loss: 0.060448713448310584\n",
      "\tTest: Average Accuracy: 0.7881724683544303\tAverage Loss: 0.05999798603855313\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8030383795309168\tAverage Loss: 0.0634422760131031\n",
      "\tTest: Average Accuracy: 0.7929193037974683\tAverage Loss: 0.062452201217303854\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8061256218905473\tAverage Loss: 0.061051649783885116\n",
      "\tTest: Average Accuracy: 0.7728441455696202\tAverage Loss: 0.10097379712387372\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8039378997867804\tAverage Loss: 0.06128773487767314\n",
      "\tTest: Average Accuracy: 0.8036985759493671\tAverage Loss: 0.059874379863583495\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8030939054726368\tAverage Loss: 0.06278009512221751\n",
      "\tTest: Average Accuracy: 0.8043908227848101\tAverage Loss: 0.05783529791515207\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8058868603411514\tAverage Loss: 0.06083839725431866\n",
      "\tTest: Average Accuracy: 0.7219145569620253\tAverage Loss: 0.09070365764824602\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8041933191186923\tAverage Loss: 0.062348373862329505\n",
      "\tTest: Average Accuracy: 0.8165545886075949\tAverage Loss: 0.05588650845558478\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8069696162046909\tAverage Loss: 0.06083473094860417\n",
      "\tTest: Average Accuracy: 0.7917325949367089\tAverage Loss: 0.06244140897711938\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8065087508884151\tAverage Loss: 0.06301153151014137\n",
      "\tTest: Average Accuracy: 0.8001384493670886\tAverage Loss: 0.05839144134916652\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8071195362473348\tAverage Loss: 0.061526047315905476\n",
      "\tTest: Average Accuracy: 0.8169501582278481\tAverage Loss: 0.056334874805360126\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8094016524520256\tAverage Loss: 0.06012213985509559\n",
      "\tTest: Average Accuracy: 0.7743275316455697\tAverage Loss: 0.06995287125601571\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8069474058280028\tAverage Loss: 0.06146559652733746\n",
      "\tTest: Average Accuracy: 0.8068631329113924\tAverage Loss: 0.059146913300308454\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8073471926083866\tAverage Loss: 0.06416046440961572\n",
      "\tTest: Average Accuracy: 0.798556170886076\tAverage Loss: 0.061110691042397615\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.7728822405828002\tAverage Loss: 0.07322348640385787\n",
      "\tTest: Average Accuracy: 0.8014240506329114\tAverage Loss: 0.060306863378660876\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.7943818852167733\tAverage Loss: 0.061369973735338944\n",
      "\tTest: Average Accuracy: 0.7652294303797469\tAverage Loss: 0.0671298306743413\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Testing BATCH_SIZE=16 on the network: It seems that with a smaller value for batch size, a better accuracy is achievable and the network is giving better results. But the point is that very small batch sizes are not appropriate because the weights might take considerable changes.\n",
    "\n",
    "##### There is not a big difference in accuracy using 16 and 32 values for BATCH_SIZE. So it will remain 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.6788\tAverage Loss: 0.08785681183674342\n",
      "\tTest: Average Accuracy: 0.8002\tAverage Loss: 0.05747391769495622\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8219833333333333\tAverage Loss: 0.05083169156562495\n",
      "\tTest: Average Accuracy: 0.829\tAverage Loss: 0.04915699129047312\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8415\tAverage Loss: 0.04569744300515685\n",
      "\tTest: Average Accuracy: 0.835\tAverage Loss: 0.04688949909988515\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8473666666666667\tAverage Loss: 0.04341992738509648\n",
      "\tTest: Average Accuracy: 0.8398\tAverage Loss: 0.045764563062228245\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.85275\tAverage Loss: 0.04189016665547729\n",
      "\tTest: Average Accuracy: 0.8484\tAverage Loss: 0.043559628588055774\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8575833333333334\tAverage Loss: 0.04088522219477235\n",
      "\tTest: Average Accuracy: 0.8318\tAverage Loss: 0.04755807801169681\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8596333333333334\tAverage Loss: 0.04003358091751618\n",
      "\tTest: Average Accuracy: 0.8437\tAverage Loss: 0.04385756679173877\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.86175\tAverage Loss: 0.03938827382854203\n",
      "\tTest: Average Accuracy: 0.8482\tAverage Loss: 0.04264879799442673\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8632666666666666\tAverage Loss: 0.0389906196852201\n",
      "\tTest: Average Accuracy: 0.8535\tAverage Loss: 0.041683371260019024\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8651833333333333\tAverage Loss: 0.03831162875355459\n",
      "\tTest: Average Accuracy: 0.8522\tAverage Loss: 0.04247148906910871\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.86555\tAverage Loss: 0.037964153851706886\n",
      "\tTest: Average Accuracy: 0.8362\tAverage Loss: 0.0458523527696223\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8681166666666666\tAverage Loss: 0.037501372089971334\n",
      "\tTest: Average Accuracy: 0.8379\tAverage Loss: 0.04622257707962319\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8687\tAverage Loss: 0.03704081273837975\n",
      "\tTest: Average Accuracy: 0.8544\tAverage Loss: 0.04226862798870761\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8706\tAverage Loss: 0.03671697867089854\n",
      "\tTest: Average Accuracy: 0.854\tAverage Loss: 0.041687091935499736\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8699166666666667\tAverage Loss: 0.03645270284341076\n",
      "\tTest: Average Accuracy: 0.8501\tAverage Loss: 0.041623918422823716\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8723833333333333\tAverage Loss: 0.03609855958634286\n",
      "\tTest: Average Accuracy: 0.8502\tAverage Loss: 0.04431955933732695\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8716833333333334\tAverage Loss: 0.0358263295625101\n",
      "\tTest: Average Accuracy: 0.8359\tAverage Loss: 0.04540058691029249\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8744833333333333\tAverage Loss: 0.03542365939459504\n",
      "\tTest: Average Accuracy: 0.853\tAverage Loss: 0.04169708681612796\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8754666666666666\tAverage Loss: 0.035257382226665655\n",
      "\tTest: Average Accuracy: 0.8555\tAverage Loss: 0.04029570062386404\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8746666666666667\tAverage Loss: 0.0350486290053126\n",
      "\tTest: Average Accuracy: 0.8501\tAverage Loss: 0.04308843267718929\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8752666666666666\tAverage Loss: 0.03495127128312754\n",
      "\tTest: Average Accuracy: 0.8574\tAverage Loss: 0.04013079302239155\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8764166666666666\tAverage Loss: 0.03475728449724155\n",
      "\tTest: Average Accuracy: 0.8603\tAverage Loss: 0.039501956246802986\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.87675\tAverage Loss: 0.034675559730994364\n",
      "\tTest: Average Accuracy: 0.8561\tAverage Loss: 0.040911350855757096\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8775666666666667\tAverage Loss: 0.03439227412331541\n",
      "\tTest: Average Accuracy: 0.8528\tAverage Loss: 0.04081660808894457\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.87675\tAverage Loss: 0.034255076721669685\n",
      "\tTest: Average Accuracy: 0.8571\tAverage Loss: 0.0404099479000694\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8787333333333334\tAverage Loss: 0.03420083343651017\n",
      "\tTest: Average Accuracy: 0.8576\tAverage Loss: 0.040433666162860746\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8773333333333333\tAverage Loss: 0.0341025091563988\n",
      "\tTest: Average Accuracy: 0.8597\tAverage Loss: 0.040626681505506225\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8769166666666667\tAverage Loss: 0.033957804900099094\n",
      "\tTest: Average Accuracy: 0.8604\tAverage Loss: 0.039824698009454734\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8799833333333333\tAverage Loss: 0.03359391502414226\n",
      "\tTest: Average Accuracy: 0.8468\tAverage Loss: 0.042167090727071956\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8800166666666667\tAverage Loss: 0.03362431462015743\n",
      "\tTest: Average Accuracy: 0.8592\tAverage Loss: 0.039453179131770655\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: The best number of epochs and overfitting\n",
    "\n",
    "Each epoch that we give to the network is a single round of optimization. With more rounds of optimization, the error on training data will reduce further and further. But the point is that the network may become overfitted to the training data and will start to lose performance after a while.\n",
    "As we can see in the drawn plots, after the 10th epoch, the results have not got better and it seems thay EPOCHS = 10 is an appropriate value to avoid over-fitting and under-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.6793666666666667\tAverage Loss: 0.08946084950997096\n",
      "\tTest: Average Accuracy: 0.8039137380191693\tAverage Loss: 0.057939594739875436\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8225666666666667\tAverage Loss: 0.05115256241894467\n",
      "\tTest: Average Accuracy: 0.8316693290734825\tAverage Loss: 0.04854711001825458\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8427833333333333\tAverage Loss: 0.045722330243376234\n",
      "\tTest: Average Accuracy: 0.770367412140575\tAverage Loss: 0.062389169176926586\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8487666666666667\tAverage Loss: 0.04358125037749141\n",
      "\tTest: Average Accuracy: 0.8441493610223643\tAverage Loss: 0.04480576065287061\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8527\tAverage Loss: 0.04212799625238813\n",
      "\tTest: Average Accuracy: 0.8406549520766773\tAverage Loss: 0.04479591857726696\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8561333333333333\tAverage Loss: 0.041254335536257306\n",
      "\tTest: Average Accuracy: 0.8401557507987221\tAverage Loss: 0.04506507546414388\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8586\tAverage Loss: 0.04026743770137931\n",
      "\tTest: Average Accuracy: 0.8311701277955271\tAverage Loss: 0.04672084486649807\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8609833333333333\tAverage Loss: 0.039588773225319174\n",
      "\tTest: Average Accuracy: 0.8483426517571885\tAverage Loss: 0.04275935059750585\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8628333333333333\tAverage Loss: 0.03893425878026587\n",
      "\tTest: Average Accuracy: 0.8498402555910544\tAverage Loss: 0.041573032744843495\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8655\tAverage Loss: 0.038462681165658645\n",
      "\tTest: Average Accuracy: 0.8484424920127795\tAverage Loss: 0.04338343808969055\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8647333333333334\tAverage Loss: 0.03802303264854727\n",
      "\tTest: Average Accuracy: 0.8473442492012779\tAverage Loss: 0.042717378580502105\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8672333333333333\tAverage Loss: 0.037497460691596436\n",
      "\tTest: Average Accuracy: 0.8539337060702875\tAverage Loss: 0.041728571312937925\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8668166666666667\tAverage Loss: 0.03755655755268744\n",
      "\tTest: Average Accuracy: 0.8513378594249201\tAverage Loss: 0.04245475072285063\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8696\tAverage Loss: 0.037054581186356995\n",
      "\tTest: Average Accuracy: 0.8532348242811502\tAverage Loss: 0.04117691272727531\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8690166666666667\tAverage Loss: 0.03683835049145975\n",
      "\tTest: Average Accuracy: 0.8525359424920128\tAverage Loss: 0.04184811337074248\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8693166666666666\tAverage Loss: 0.03656760495545372\n",
      "\tTest: Average Accuracy: 0.8472444089456869\tAverage Loss: 0.043798148078575426\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8701833333333333\tAverage Loss: 0.036308925739686915\n",
      "\tTest: Average Accuracy: 0.851138178913738\tAverage Loss: 0.04224292705516769\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8696\tAverage Loss: 0.036266802921932\n",
      "\tTest: Average Accuracy: 0.8459464856230032\tAverage Loss: 0.042284516018665314\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8706833333333334\tAverage Loss: 0.03598856732425538\n",
      "\tTest: Average Accuracy: 0.8554313099041534\tAverage Loss: 0.0411898135253004\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8716333333333334\tAverage Loss: 0.0358088196833387\n",
      "\tTest: Average Accuracy: 0.8505391373801917\tAverage Loss: 0.04204957767875852\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8715833333333334\tAverage Loss: 0.03551837527548109\n",
      "\tTest: Average Accuracy: 0.8409544728434505\tAverage Loss: 0.045714042614547805\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8728\tAverage Loss: 0.03546652926845977\n",
      "\tTest: Average Accuracy: 0.8557308306709265\tAverage Loss: 0.04101532415326366\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8725\tAverage Loss: 0.035495587539613085\n",
      "\tTest: Average Accuracy: 0.8525359424920128\tAverage Loss: 0.041947979727201636\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8731333333333333\tAverage Loss: 0.035437604651478355\n",
      "\tTest: Average Accuracy: 0.8505391373801917\tAverage Loss: 0.04237655127660221\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8716166666666667\tAverage Loss: 0.03551599549644359\n",
      "\tTest: Average Accuracy: 0.8484424920127795\tAverage Loss: 0.042611775684724525\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8737666666666667\tAverage Loss: 0.03534850845205363\n",
      "\tTest: Average Accuracy: 0.8433506389776357\tAverage Loss: 0.044515085705641985\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8734666666666666\tAverage Loss: 0.03522295552037089\n",
      "\tTest: Average Accuracy: 0.8558306709265175\tAverage Loss: 0.040505763057033316\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8744666666666666\tAverage Loss: 0.034729055033281296\n",
      "\tTest: Average Accuracy: 0.8508386581469649\tAverage Loss: 0.04159696233957478\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.87485\tAverage Loss: 0.0346838445740477\n",
      "\tTest: Average Accuracy: 0.8482428115015974\tAverage Loss: 0.04235709456364196\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8748166666666667\tAverage Loss: 0.034633345298908935\n",
      "\tTest: Average Accuracy: 0.8483426517571885\tAverage Loss: 0.04152041495135086\n",
      "Epoch 31:\n",
      "\tTrain: Average Accuracy: 0.8765\tAverage Loss: 0.03466047352642881\n",
      "\tTest: Average Accuracy: 0.8377595846645367\tAverage Loss: 0.04697751975730159\n",
      "Epoch 32:\n",
      "\tTrain: Average Accuracy: 0.87575\tAverage Loss: 0.034509522638857315\n",
      "\tTest: Average Accuracy: 0.8547324281150159\tAverage Loss: 0.041427265377389756\n",
      "Epoch 33:\n",
      "\tTrain: Average Accuracy: 0.8763333333333333\tAverage Loss: 0.03447683558897395\n",
      "\tTest: Average Accuracy: 0.849341054313099\tAverage Loss: 0.044268369155823224\n",
      "Epoch 34:\n",
      "\tTrain: Average Accuracy: 0.8760666666666667\tAverage Loss: 0.03420422037823449\n",
      "\tTest: Average Accuracy: 0.8490415335463258\tAverage Loss: 0.043309292769271354\n",
      "Epoch 35:\n",
      "\tTrain: Average Accuracy: 0.8783\tAverage Loss: 0.034095098487171634\n",
      "\tTest: Average Accuracy: 0.8430511182108626\tAverage Loss: 0.044944702257806494\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(20, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)\n",
    "\n",
    "# Plots\n",
    "\n",
    "x_axis = [i for i in range(EPOCHS)]\n",
    "mtplot.plot(x_axis, log['train_accuracy'], color=\"blue\")\n",
    "mtplot.plot(x_axis, log['test_accuracy'], color=\"red\")\n",
    "mtplot.title(\"Accuracy for each epoch\")\n",
    "mtplot.xlabel(\"Epoch's num\")\n",
    "mtplot.ylabel(\"Accuracy\")\n",
    "mtplot.show()\n",
    "\n",
    "x_axis = [i for i in range(EPOCHS)]\n",
    "mtplot.plot(x_axis, log['train_loss'], color=\"blue\")\n",
    "mtplot.plot(x_axis, log['test_loss'], color=\"red\")\n",
    "mtplot.title(\"Loss in each epoch\")\n",
    "mtplot.xlabel(\"Epoch's num\")\n",
    "mtplot.ylabel(\"Loss\")\n",
    "mtplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 4: Reduced dimension method\n",
    "\n",
    "* For this part, a method named \"get_2Dout\" has been defined which is called after the network gets trained and it will get the whole input and returns the output of the 2-neuron layer.\n",
    "\n",
    "* Besides, a new network is trained below with different layers and hyper-parameters which has reached the minimum-accuracy(75%) at the last epochs. So it is used to get the 2D output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.18733333333333332\tAverage Loss: 0.2260717076846167\n",
      "\tTest: Average Accuracy: 0.25179712460063897\tAverage Loss: 0.18498079815230545\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.3518833333333333\tAverage Loss: 0.16574661233926546\n",
      "\tTest: Average Accuracy: 0.577076677316294\tAverage Loss: 0.11915787609063962\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6287833333333334\tAverage Loss: 0.10228599004173894\n",
      "\tTest: Average Accuracy: 0.65814696485623\tAverage Loss: 0.09438757830321087\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.6796333333333333\tAverage Loss: 0.09065441986989892\n",
      "\tTest: Average Accuracy: 0.7071685303514377\tAverage Loss: 0.08360646776694873\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.6916333333333333\tAverage Loss: 0.08324428912971915\n",
      "\tTest: Average Accuracy: 0.6988817891373802\tAverage Loss: 0.0803261933618978\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.6965833333333333\tAverage Loss: 0.07817170512916276\n",
      "\tTest: Average Accuracy: 0.6974840255591054\tAverage Loss: 0.07889369008039959\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.7090666666666666\tAverage Loss: 0.07457100286282951\n",
      "\tTest: Average Accuracy: 0.7190495207667732\tAverage Loss: 0.07443976369703842\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.7143333333333334\tAverage Loss: 0.072582563424545\n",
      "\tTest: Average Accuracy: 0.7221445686900958\tAverage Loss: 0.07436578187152482\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.7190833333333333\tAverage Loss: 0.07143782475961526\n",
      "\tTest: Average Accuracy: 0.7116613418530351\tAverage Loss: 0.07599955208196361\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.7250333333333333\tAverage Loss: 0.06954551637183666\n",
      "\tTest: Average Accuracy: 0.7327276357827476\tAverage Loss: 0.07136854396496198\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.72625\tAverage Loss: 0.06977121708693104\n",
      "\tTest: Average Accuracy: 0.7327276357827476\tAverage Loss: 0.07184244757602899\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.7298666666666667\tAverage Loss: 0.06858804246421746\n",
      "\tTest: Average Accuracy: 0.7350239616613419\tAverage Loss: 0.07213185014034149\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.72485\tAverage Loss: 0.07058438995131261\n",
      "\tTest: Average Accuracy: 0.7248402555910544\tAverage Loss: 0.07178451232170402\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.7360166666666667\tAverage Loss: 0.06771997182887296\n",
      "\tTest: Average Accuracy: 0.737020766773163\tAverage Loss: 0.0708716054642831\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.7416\tAverage Loss: 0.06664813549017978\n",
      "\tTest: Average Accuracy: 0.7413138977635783\tAverage Loss: 0.07082764372995268\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.7449166666666667\tAverage Loss: 0.06630412851584806\n",
      "\tTest: Average Accuracy: 0.7476038338658147\tAverage Loss: 0.06913015126208173\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.7522666666666666\tAverage Loss: 0.0644488726538578\n",
      "\tTest: Average Accuracy: 0.7509984025559105\tAverage Loss: 0.07002472331561911\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.7578\tAverage Loss: 0.06321530967741827\n",
      "\tTest: Average Accuracy: 0.7561900958466453\tAverage Loss: 0.06888096703654066\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.74705\tAverage Loss: 0.06781394715086701\n",
      "\tTest: Average Accuracy: 0.7528953674121406\tAverage Loss: 0.07088519486220897\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.7564\tAverage Loss: 0.06491624072440577\n",
      "\tTest: Average Accuracy: 0.7576876996805112\tAverage Loss: 0.06927954452239973\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.7670166666666667\tAverage Loss: 0.06169565747344762\n",
      "\tTest: Average Accuracy: 0.7605830670926518\tAverage Loss: 0.06819829358460229\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.7523833333333333\tAverage Loss: 0.06684829893533331\n",
      "\tTest: Average Accuracy: 0.7519968051118211\tAverage Loss: 0.06805780548238217\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.7613333333333333\tAverage Loss: 0.06424578884675451\n",
      "\tTest: Average Accuracy: 0.7568889776357828\tAverage Loss: 0.06850521265882539\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.7610166666666667\tAverage Loss: 0.06488598276969637\n",
      "\tTest: Average Accuracy: 0.762779552715655\tAverage Loss: 0.0671315402277742\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.7507\tAverage Loss: 0.0703011379725069\n",
      "\tTest: Average Accuracy: 0.7611821086261981\tAverage Loss: 0.07104406979372117\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.0025\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "norm_train_data = data_preprocessor(train_data.copy())\n",
    "norm_test_data = data_preprocessor(test_data.copy())\n",
    "norm_train_labels = label_preprocessor(train_labels.copy())\n",
    "norm_test_labels = label_preprocessor(test_labels.copy())\n",
    "\n",
    "TRAINLOADER = Dataloader(norm_train_data, norm_train_labels, 10, batch_size=BATCH_SIZE, shuffle=False)\n",
    "TESTLOADER = Dataloader(norm_test_data, norm_test_labels, 10, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(784, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(2, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mtplot\n",
    "\n",
    "NUMBER_OF_CLASSES = 10\n",
    "\n",
    "\n",
    "def onehot_to_normal(labels):\n",
    "    classes = []\n",
    "    for row in labels:\n",
    "        index = np.argmax(row)\n",
    "        classes.append(index)\n",
    "    return classes\n",
    "    \n",
    "layer2D_trainout = network.get_2Dout(norm_train_data)\n",
    "layer2D_testout = network.get_2Dout(norm_test_data)\n",
    "\n",
    "first_neuron_train = layer2D_trainout[:,0].tolist()\n",
    "first_neuron_test = layer2D_testout[:,0].tolist()\n",
    "second_neuron_train = layer2D_trainout[:,1].tolist()\n",
    "second_neuron_test = layer2D_testout[:,1].tolist()\n",
    "\n",
    "normal_train_labels = norm_train_labels.copy().tolist()\n",
    "normal_test_labels = norm_test_labels.copy().tolist()\n",
    "\n",
    "train_x_axis = [[] for i in range(NUMBER_OF_CLASSES)]\n",
    "train_y_axis = [[] for i in range(NUMBER_OF_CLASSES)]\n",
    "test_x_axis = [[] for i in range(NUMBER_OF_CLASSES)]\n",
    "test_y_axis = [[] for i in range(NUMBER_OF_CLASSES)]\n",
    "\n",
    "for i in range(len(normal_train_labels)):\n",
    "    train_x_axis[normal_train_labels[i][0]].append(first_neuron_train[i])\n",
    "    train_y_axis[normal_train_labels[i][0]].append(second_neuron_train[i])\n",
    "\n",
    "for i in range(len(normal_test_labels)):\n",
    "    test_x_axis[normal_test_labels[i][0]].append(first_neuron_test[i])\n",
    "    test_y_axis[normal_test_labels[i][0]].append(second_neuron_test[i])\n",
    "\n",
    "colors_list = [\"blue\", \"red\", 'gray', 'green', 'yellow', 'orange', 'green', 'brown', 'cyan', 'purple']\n",
    "\n",
    "for i in range(NUMBER_OF_CLASSES):\n",
    "    mtplot.scatter(train_x_axis[i], train_y_axis[i], color = colors_list[i], label = str(i))\n",
    "    mtplot.title(\"Train data plot\")\n",
    "    mtplot.xlabel(\"First neuron output\")\n",
    "    mtplot.ylabel(\"Second neuron output\")\n",
    "    mtplot.legend()\n",
    "mtplot.show()\n",
    "\n",
    "for i in range(NUMBER_OF_CLASSES):\n",
    "    mtplot.scatter(test_x_axis[i], test_y_axis[i], color = colors_list[i], label = str(i))\n",
    "    mtplot.title(\"Test data plot\")\n",
    "    mtplot.xlabel(\"First neuron output\")\n",
    "    mtplot.ylabel(\"Second neuron output\")\n",
    "    mtplot.legend()\n",
    "mtplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>In this part, using the output of the added method I have drawn the plot of the results of that layer. The color of each class's data is separated from the others. Based on these plots, it seems that class number 1, 8 and 9 are classified and seperated better than others, but classifying and separating class number 3, 4 and 0 from rach other seems to be difficult for the designed network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
